{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a135a10-6a1c-4839-a46d-8e808d783bac",
   "metadata": {},
   "source": [
    "# Comprehensive Analysis of Greenland Glacier-Ocean Interactions: Summer (June–July–August, JJA) Dynamics (2010–2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f78b2d-156f-48d6-a4e6-eace39dbe7a5",
   "metadata": {},
   "source": [
    "This computational notebook presents an integrated computational framework to investigate the dynamic interplay between Greenland’s marine-terminating glaciers and adjacent oceanographic conditions, focusing on four critical outlet glaciers (Helheim, Storebjørn, Daugaard-Jensen, and Waltershausen) spanning the 69°N latitudinal divide (Seale et al., 2011). Leveraging multi-source datasets including ORAS5 ocean reanalysis (CDS, 2021), IBCAO Version 5.0 bathymetry (Jakobsson et al., 2024), and glacier hydrographic records (Karlsson et al., 2023), the workflow systematically addresses polar data challenges through three interconnected analytical pipelines: (1) ocean temperature extraction at 300m depth using Euclidean distance-based nearest grid point search with progressive spatial search (1–3° radii) (Section 1), (2) high-resolution geospatial visualization integrating Cartopy, Rasterio, and Google Terrain tiles (Section 2), and (3) time-series analysis of summer (JJA) glacier dynamics—runoff, ice discharge, and submarine melt rates—with NE/SE regional partitioning (Sections 3–4). The 300m-depth ocean potential temperature visualization (Section 4) presents Section 1's extracted data as regional time series, while Section 5 synthesizes these components by computing submarine melt rates using the Slater & Straneo (2022) parameterization (ṁ = 0.142 × Q⁰·³¹ × TF¹·¹⁹, where Q is subglacial discharge in m³/s and TF is thermal forcing in °C), followed by statistical correlation testing between estimated melt rates and observed ice discharge. Technical innovations include automated coordinate system validation, multi-level data gap handling, and publication-ready 300DPI outputs with standardized metadata tags. By integrating multi-scale datasets within a reproducible computational framework, this study advances our capacity to quantify glacier-ocean interactions while establishing a template for future high-latitude cryosphere-hydrosphere studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce20362-bd4c-47d9-802d-3f8b3af03215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kyle/Documents/dissertation'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abcb78cc-bd5c-4783-bd2e-af4334ca0e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m 'repo.anaconda.com', a commercial channel hosted by Anaconda.com, is used.\n",
      "    \n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Please make sure you understand Anaconda Terms of Services.\n",
      "    \n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m See: https://legal.anaconda.com/policies/en/\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━━╸━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\n",
      "conda-forge/osx-arm64 ━╸━━━━━━━━━━━━━━━╸━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\n",
      "pkgs/main/noarch      ━━━━━━━━━━━━━━━╸━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\n",
      "pkgs/main/osx-arm64   ━━━━━━━━━━━╸━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/r/noarch         ╸━━━━━━━━━━━━━━━╸━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\n",
      "conda-forge/noarch    ╸━━━━━━━━━━━━━━━╸━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "conda-forge/osx-arm64 ━━━╸━━━━━━━━━━━━━━━╸━━   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "pkgs/main/osx-arm64   ━━━━━━━━━━━━━━━━━━━━━━  75.8kB /   5.9MB @ 493.2kB/s  0.2s\n",
      "pkgs/r/osx-arm64      ━━━━━━━╸━━━━━━━━━━━━━━   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.3s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━━━━━━━━━━ 240.2kB /  24.6MB @ 919.4kB/s  0.2s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━━━━━━━━━━━ 248.9kB /  20.3MB @ 953.0kB/s  0.2s\n",
      "pkgs/main/osx-arm64   ╸━━━━━━━━━━━━━━━━━━━━━ 494.4kB /   5.9MB @   1.9MB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━━━━━━━━━━ 614.4kB /  24.6MB @   1.7MB/s  0.3s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━━━━━━━━━━━ 692.7kB /  20.3MB @   1.9MB/s  0.3s\n",
      "pkgs/main/osx-arm64   ━━╸━━━━━━━━━━━━━━━━━━━   1.0MB /   5.9MB @   2.7MB/s  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━━━━━━━━━━   1.0MB /  24.6MB @   2.2MB/s  0.4s\n",
      "conda-forge/osx-arm64 ╸━━━━━━━━━━━━━━━━━━━━━   1.3MB /  20.3MB @   2.8MB/s  0.4s\n",
      "pkgs/main/osx-arm64   ━━━━╸━━━━━━━━━━━━━━━━━   1.6MB /   5.9MB @   3.2MB/s  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\n",
      "conda-forge/noarch    ╸━━━━━━━━━━━━━━━━━━━━━   1.5MB /  24.6MB @   2.7MB/s  0.5s\n",
      "conda-forge/osx-arm64 ╸━━━━━━━━━━━━━━━━━━━━━   2.0MB /  20.3MB @   3.5MB/s  0.5s\n",
      "pkgs/main/osx-arm64   ━━━━━━╸━━━━━━━━━━━━━━━   2.0MB /   5.9MB @   3.5MB/s  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\n",
      "conda-forge/noarch    ╸━━━━━━━━━━━━━━━━━━━━━   2.3MB /  24.6MB @   3.4MB/s  0.6s\n",
      "conda-forge/osx-arm64 ━╸━━━━━━━━━━━━━━━━━━━━   2.5MB /  20.3MB @   3.7MB/s  0.6s\n",
      "pkgs/main/osx-arm64   ━━━━━━━━╸━━━━━━━━━━━━━   2.7MB /   5.9MB @   3.9MB/s  0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\n",
      "conda-forge/noarch    ━╸━━━━━━━━━━━━━━━━━━━━   2.9MB /  24.6MB @   3.7MB/s  0.7s\n",
      "conda-forge/osx-arm64 ━━╸━━━━━━━━━━━━━━━━━━━   3.0MB /  20.3MB @   3.9MB/s  0.7s\n",
      "pkgs/main/osx-arm64   ━━━━━━━━━━━╸━━━━━━━━━━   3.3MB /   5.9MB @   4.2MB/s  0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\n",
      "conda-forge/noarch    ━╸━━━━━━━━━━━━━━━━━━━━   3.4MB /  24.6MB @   3.9MB/s  0.8s\n",
      "conda-forge/osx-arm64 ━━╸━━━━━━━━━━━━━━━━━━━   3.6MB /  20.3MB @   4.1MB/s  0.8s\n",
      "pkgs/main/osx-arm64   ━━━━━━━━━━━━━╸━━━━━━━━   3.8MB /   5.9MB @   4.3MB/s  0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\n",
      "conda-forge/noarch    ━━╸━━━━━━━━━━━━━━━━━━━   4.0MB /  24.6MB @   4.1MB/s  0.9s\n",
      "conda-forge/osx-arm64 ━━━╸━━━━━━━━━━━━━━━━━━   4.1MB /  20.3MB @   4.2MB/s  0.9s\n",
      "pkgs/main/osx-arm64   ━━━━━━━━━━━━━━╸━━━━━━━   4.3MB /   5.9MB @   4.3MB/s  1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n",
      "conda-forge/noarch    ━━╸━━━━━━━━━━━━━━━━━━━   4.6MB /  24.6MB @   4.2MB/s  1.0s\n",
      "conda-forge/osx-arm64 ━━━╸━━━━━━━━━━━━━━━━━━   4.6MB /  20.3MB @   4.3MB/s  1.0s\n",
      "pkgs/main/osx-arm64   ━━━━━━━━━━━━━━━━╸━━━━━   4.8MB /   5.9MB @   4.4MB/s  1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\n",
      "conda-forge/noarch    ━━━╸━━━━━━━━━━━━━━━━━━   5.2MB /  24.6MB @   4.4MB/s  1.1s\n",
      "conda-forge/osx-arm64 ━━━━╸━━━━━━━━━━━━━━━━━   5.2MB /  20.3MB @   4.4MB/s  1.1s\n",
      "pkgs/main/osx-arm64   ━━━━━━━━━━━━━━━━━╸━━━━   5.1MB /   5.9MB @   4.4MB/s  1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\n",
      "conda-forge/noarch    ━━━━╸━━━━━━━━━━━━━━━━━   5.8MB /  24.6MB @   4.5MB/s  1.2s\n",
      "conda-forge/osx-arm64 ━━━━╸━━━━━━━━━━━━━━━━━   5.6MB /  20.3MB @   4.4MB/s  1.2s\n",
      "pkgs/main/osx-arm64   ━━━━━━━━━━━━━━━━━━━╸━━   5.6MB /   5.9MB @   4.4MB/s  1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/osx-arm64                                  5.9MB @   4.4MB/s  1.3s\n",
      "[+] 1.4s\n",
      "conda-forge/noarch    ━━━━╸━━━━━━━━━━━━━━━━━   6.3MB /  24.6MB @   4.6MB/s  1.3s\n",
      "conda-forge/osx-arm64 ━━━━━╸━━━━━━━━━━━━━━━━   6.1MB /  20.3MB @   4.4MB/s  1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\n",
      "conda-forge/noarch    ━━━━━╸━━━━━━━━━━━━━━━━   7.0MB /  24.6MB @   4.7MB/s  1.4s\n",
      "conda-forge/osx-arm64 ━━━━━━╸━━━━━━━━━━━━━━━   6.5MB /  20.3MB @   4.4MB/s  1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\n",
      "conda-forge/noarch    ━━━━━╸━━━━━━━━━━━━━━━━   7.7MB /  24.6MB @   4.9MB/s  1.5s\n",
      "conda-forge/osx-arm64 ━━━━━━╸━━━━━━━━━━━━━━━   7.2MB /  20.3MB @   4.5MB/s  1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
      "conda-forge/noarch    ━━━━━━╸━━━━━━━━━━━━━━━   8.6MB /  24.6MB @   5.1MB/s  1.6s\n",
      "conda-forge/osx-arm64 ━━━━━━━╸━━━━━━━━━━━━━━   7.9MB /  20.3MB @   4.7MB/s  1.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
      "conda-forge/noarch    ━━━━━━━╸━━━━━━━━━━━━━━   9.4MB /  24.6MB @   5.3MB/s  1.7s\n",
      "conda-forge/osx-arm64 ━━━━━━━━╸━━━━━━━━━━━━━   8.7MB /  20.3MB @   4.9MB/s  1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
      "conda-forge/noarch    ━━━━━━━━╸━━━━━━━━━━━━━  10.3MB /  24.6MB @   5.4MB/s  1.8s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━╸━━━━━━━━━━━━   9.5MB /  20.3MB @   5.0MB/s  1.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
      "conda-forge/noarch    ━━━━━━━━╸━━━━━━━━━━━━━  10.8MB /  24.6MB @   5.6MB/s  1.9s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━╸━━━━━━━━━━━━   9.9MB /  20.3MB @   5.1MB/s  1.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
      "conda-forge/noarch    ━━━━━━━━━╸━━━━━━━━━━━━  11.6MB /  24.6MB @   5.6MB/s  2.0s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━╸━━━━━━━━━━━  10.6MB /  20.3MB @   5.2MB/s  2.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
      "conda-forge/noarch    ━━━━━━━━━━╸━━━━━━━━━━━  12.4MB /  24.6MB @   5.7MB/s  2.1s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━╸━━━━━━━━━━  11.3MB /  20.3MB @   5.2MB/s  2.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
      "conda-forge/noarch    ━━━━━━━━━━╸━━━━━━━━━━━  13.3MB /  24.6MB @   5.9MB/s  2.2s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━╸━━━━━━━━━━  12.0MB /  20.3MB @   5.3MB/s  2.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
      "conda-forge/noarch    ━━━━━━━━━━━╸━━━━━━━━━━  14.2MB /  24.6MB @   6.0MB/s  2.3s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━╸━━━━━━━━━  12.7MB /  20.3MB @   5.4MB/s  2.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━╸━━━━━━━━━  15.2MB /  24.6MB @   6.1MB/s  2.4s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━━╸━━━━━━━━  13.4MB /  20.3MB @   5.4MB/s  2.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━╸━━━━━━━━  16.0MB /  24.6MB @   6.2MB/s  2.5s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━━━╸━━━━━━━  14.1MB /  20.3MB @   5.5MB/s  2.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━╸━━━━━━━━  17.0MB /  24.6MB @   6.4MB/s  2.6s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━━━╸━━━━━━━  14.8MB /  20.3MB @   5.6MB/s  2.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━━╸━━━━━━━  17.9MB /  24.6MB @   6.5MB/s  2.7s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━━━━╸━━━━━━  15.5MB /  20.3MB @   5.6MB/s  2.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━━━╸━━━━━━  19.0MB /  24.6MB @   6.6MB/s  2.8s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━━━━━╸━━━━━  16.2MB /  20.3MB @   5.6MB/s  2.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━━━━╸━━━━━  19.8MB /  24.6MB @   6.6MB/s  2.9s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━━━━━━╸━━━━  16.8MB /  20.3MB @   5.7MB/s  2.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━━━━━╸━━━━  20.7MB /  24.6MB @   6.7MB/s  3.0s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━━━━━━╸━━━━  17.5MB /  20.3MB @   5.7MB/s  3.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━━━━━━╸━━━  21.6MB /  24.6MB @   6.8MB/s  3.1s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━━━━━━━╸━━━  18.2MB /  20.3MB @   5.7MB/s  3.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━━━━━━━╸━━  22.7MB /  24.6MB @   6.9MB/s  3.2s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━━━━━━━━╸━━  19.0MB /  20.3MB @   5.8MB/s  3.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
      "conda-forge/noarch    ━━━━━━━━━━━━━━━━━━━━╸━  23.7MB /  24.6MB @   7.0MB/s  3.3s\n",
      "conda-forge/osx-arm64 ━━━━━━━━━━━━━━━━━━━━╸━  19.7MB /  20.3MB @   5.8MB/s  3.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/osx-arm64                               20.3MB @   5.8MB/s  3.4s\n",
      "conda-forge/noarch                                  24.6MB @   7.1MB/s  3.4s\n",
      "\u001b[?25h\n",
      "Pinned packages:\n",
      "\n",
      "  - python=3.11\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/anaconda3\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "\n",
      "Transaction starting\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n",
      "Transaction finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mamba install -c conda-forge netcdf4 -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93b5cc8-b511-4e3b-8366-6fa0b4afd8ef",
   "metadata": {},
   "source": [
    "## Section 1: Ocean Temperature Extraction Pipeline from ORAS5 for Greenland Glaciers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacabcc1-db57-4085-a8ad-e5a0463c7489",
   "metadata": {},
   "source": [
    "This pipeline extracts monthly ocean temperature data at 300m depth from ORAS5 reanalysis (CDS, 2021) for four Greenland outlet glaciers spanning 2010-2020. I focus on 300m depth because in-situ observations from Sermilik Fjord show that waters at this depth maintain consistently warm temperatures (~4°C) year-round with minimal seasonal variability, in contrast to the highly variable surface layer (Straneo et al., 2010). This depth corresponds to the zone where submarine melt rates typically maximize (Seale et al., 2011) and captures the core of intruding Atlantic Water masses in southeast Greenland fjords. Seale et al. (2011) demonstrated that the retreat of East Greenland glaciers south of 69°N was strongly influenced by warming of subsurface coastal waters (100m to bottom), emphasizing the importance of deep-layer thermal forcing rather than surface conditions in driving glacier dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b66a4-69c3-4dc7-94ed-39507be00678",
   "metadata": {},
   "source": [
    "The methodology employs a two-stage approach. First, we identified the nearest valid ocean grid point with 300m depth data for each glacier using a progressive spatial search algorithm (1-3° radii) centered on original glacier coordinates. This yielded final ocean points at distances ranging from 0 km (Daugaard-Jensen) to 137 km (Waltershausen), with validation temperatures showing expected thermal dichotomy: SE glaciers (Helheim 4.33°C, Storebjoern 4.60°C) versus NE glaciers (Daugaard-Jensen 0.06°C, Waltershausen -0.04°C) in July 2015. Second, we systematically processed 33 monthly NetCDF files filtering for summer months (June–July–August, JJA) and extracting temperatures at each glacier's finalized ocean point using Euclidean distance minimization on the ORAS5 curvilinear grid, yielding 132 data points (4 glaciers × 3 months × 11 years). Regional averages were calculated as SE = mean(Helheim, Storebjoern) and NE = mean(Daugaard-Jensen, Waltershausen), producing an 11-year time series with SE regional mean of 4.75°C and NE regional mean of 0.06°C—a 4.70°C temperature difference that clearly delineates the 69°N oceanographic boundary identified by Seale et al. (2011)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ddfb2f-bf7d-4d4f-97bc-f5b7bac38210",
   "metadata": {},
   "source": [
    "The large spatial offsets between glacier termini and ocean points reflect ORAS5's ~25km resolution relative to narrow fjord geometries but remain physically justified as they capture regional water mass properties (Atlantic versus Polar Water) rather than localized fjord circulation. All extracted data is stored in glacier_temperature_300m_2010_2020.csv for subsequent time series visualization and correlation analysis with glacier discharge patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c938e21-e79b-46bf-aadd-1ddece606100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINDING REPLACEMENT COORDINATES WITH 300m DATA ===\n",
      "Target depth: 300m, Closest available: 300.9m\n",
      "\n",
      "Processing Helheim Gletsjer...\n",
      "  Original: 66.3500°N, -38.2000°E\n",
      "  Found at 2.0° range: 65.2358°N, -37.9326°E\n",
      "     Temperature: 4.33°C, Distance: 124.84 km\n",
      "Processing Storebjoern...\n",
      "  Original: 63.7167°N, -41.6497°E\n",
      "  Found at 1.0° range: 62.9264°N, -40.8969°E\n",
      "     Temperature: 4.66°C, Distance: 95.83 km\n",
      "Processing Daugaard-Jensen Gletsjer...\n",
      "  Original: 71.8706°N, -28.7011°E\n",
      "  Found at 4.0° range: 71.1908°N, -25.1324°E\n",
      "     Temperature: 0.01°C, Distance: 147.24 km\n",
      "Processing Waltershausen Gletsjer...\n",
      "  Original: 73.9000°N, -24.4167°E\n",
      "  Found at 3.0° range: 72.0131°N, -22.0269°E\n",
      "     Temperature: -0.04°C, Distance: 224.58 km\n",
      "\n",
      "============================================================\n",
      "FINAL REPLACEMENT COORDINATES:\n",
      "============================================================\n",
      "  Helheim Gletsjer: {'lat': 65.2358, 'lon': -37.9326}  # Temp: 4.33°C, Dist: 124.8 km\n",
      "  Storebjoern: {'lat': 62.9264, 'lon': -40.8969}  # Temp: 4.66°C, Dist: 95.8 km\n",
      "  Daugaard-Jensen Gletsjer: {'lat': 71.1908, 'lon': -25.1324}  # Temp: 0.01°C, Dist: 147.2 km\n",
      "  Waltershausen Gletsjer: {'lat': 72.0131, 'lon': -22.0269}  # Temp: -0.04°C, Dist: 224.6 km\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 1, Code 1: Ocean Data Point Identification for ORAS5 Extraction\n",
    "# =============================================================================\n",
    "# This script identifies the nearest valid ocean grid point with 300m-depth\n",
    "# data for each of four Greenland outlet glaciers. Because ORAS5 (~25 km\n",
    "# resolution) does not resolve narrow fjord geometries, glacier terminus\n",
    "# coordinates often fall on land-masked grid cells. A progressive spatial\n",
    "# search (1°, 2°, 3° radii) centred on each glacier locates the closest\n",
    "# ocean cell that contains valid temperature data at the target depth.\n",
    "#\n",
    "# The resulting \"replacement coordinates\" are used in all subsequent\n",
    "# temperature extraction steps (Section 1 Code 2, Section 4, Section 5).\n",
    "#\n",
    "# Data source: ORAS5 ocean reanalysis (CDS, 2021)\n",
    "# Target depth: 300m — captures intruding Atlantic Water and minimises\n",
    "#               seasonal surface variability (Straneo et al., 2010)\n",
    "# =============================================================================\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "\n",
    "def find_replacement_coordinates():\n",
    "    \"\"\"\n",
    "    Identify the nearest valid ORAS5 ocean grid point at 300m depth\n",
    "    for each glacier terminus.\n",
    "\n",
    "    Method:\n",
    "        1. Open a sample ORAS5 NetCDF file (July 2015).\n",
    "        2. Find the depth index closest to 300m.\n",
    "        3. For each glacier, progressively expand a spatial search\n",
    "           window (1°→2°→3°) until a non-NaN ocean cell is found.\n",
    "        4. Among valid cells, select the one with the smallest\n",
    "           geodesic distance to the original glacier coordinates.\n",
    "\n",
    "    Returns:\n",
    "        dict: Replacement coordinates for each glacier, including\n",
    "              latitude, longitude, distance from original, and\n",
    "              a sample temperature value for validation.\n",
    "    \"\"\"\n",
    "    base_dir = \"/Users/kyle/Documents/dissertation/ORAS5/votemper\"\n",
    "\n",
    "    # Original glacier terminus coordinates (Source: Google Earth, 2025)\n",
    "    original_glacier_locations = {\n",
    "        \"Helheim Gletsjer\":         {\"lat\": 66.3500, \"lon\": -38.2000},   # 66°21'00\"N, 38°12'00\"W\n",
    "        \"Storebjoern\":              {\"lat\": 63.7167, \"lon\": -41.6497},   # 63°43'00\"N, 41°38'59\"W\n",
    "        \"Daugaard-Jensen Gletsjer\": {\"lat\": 71.8706, \"lon\": -28.7011},   # 71°52'14\"N, 28°42'04\"W\n",
    "        \"Waltershausen Gletsjer\":   {\"lat\": 73.9000, \"lon\": -24.4167},   # 73°54'00\"N, 24°25'00\"W\n",
    "    }\n",
    "\n",
    "    print(\"=== FINDING REPLACEMENT COORDINATES WITH 300m DATA ===\")\n",
    "\n",
    "    # Use July 2015 (OPER) as the sample file for grid inspection\n",
    "    sample_file = \"votemper_control_monthly_highres_3D_201507_OPER_v0.1.nc\"\n",
    "    file_path = os.path.join(base_dir, sample_file)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"  Sample file not found: {sample_file}\")\n",
    "        return original_glacier_locations\n",
    "\n",
    "    replacement_coordinates = {}\n",
    "\n",
    "    with xr.open_dataset(file_path) as ds:\n",
    "        # Find depth index closest to 300m\n",
    "        depth_idx = np.abs(ds.deptht.values - 300).argmin()\n",
    "        actual_depth = ds.deptht.values[depth_idx]\n",
    "        print(f\"Target depth: 300m, Closest available: {actual_depth:.1f}m\\n\")\n",
    "\n",
    "        for glacier, original_pos in original_glacier_locations.items():\n",
    "            print(f\"Processing {glacier}...\")\n",
    "            original_lat = original_pos['lat']\n",
    "            original_lon = original_pos['lon']\n",
    "            print(f\"  Original: {original_lat:.4f}°N, {original_lon:.4f}°E\")\n",
    "\n",
    "            # Progressive spatial search with expanding radii\n",
    "            search_ranges = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "            found_point = None\n",
    "\n",
    "            for search_range in search_ranges:\n",
    "                search_lat_min = original_lat - search_range\n",
    "                search_lat_max = original_lat + search_range\n",
    "                search_lon_min = original_lon - search_range\n",
    "                search_lon_max = original_lon + search_range\n",
    "\n",
    "                # Create spatial mask within search window\n",
    "                region_mask = (\n",
    "                    (ds.nav_lat >= search_lat_min) & (ds.nav_lat <= search_lat_max) &\n",
    "                    (ds.nav_lon >= search_lon_min) & (ds.nav_lon <= search_lon_max)\n",
    "                )\n",
    "\n",
    "                # Create data availability mask (non-NaN at 300m depth)\n",
    "                data_mask = ~np.isnan(ds.votemper.isel(time_counter=0, deptht=depth_idx))\n",
    "                valid_mask = region_mask & data_mask\n",
    "\n",
    "                if valid_mask.any():\n",
    "                    # Collect all valid ocean points in the search window\n",
    "                    valid_points = []\n",
    "                    valid_indices = np.where(valid_mask.values)\n",
    "\n",
    "                    for i in range(len(valid_indices[0])):\n",
    "                        y, x = valid_indices[0][i], valid_indices[1][i]\n",
    "                        lat = ds.nav_lat.values[y, x]\n",
    "                        lon = ds.nav_lon.values[y, x]\n",
    "                        temp = ds.votemper.isel(\n",
    "                            time_counter=0, deptht=depth_idx, y=y, x=x\n",
    "                        ).values.item()\n",
    "                        valid_points.append((lat, lon, temp))\n",
    "\n",
    "                    # Select the point closest to the original glacier position\n",
    "                    best_point = min(\n",
    "                        valid_points,\n",
    "                        key=lambda p: geodesic(\n",
    "                            (original_lat, original_lon), (p[0], p[1])\n",
    "                        ).km\n",
    "                    )\n",
    "\n",
    "                    best_lat, best_lon, best_temp = best_point\n",
    "                    distance = geodesic(\n",
    "                        (original_lat, original_lon), (best_lat, best_lon)\n",
    "                    ).km\n",
    "\n",
    "                    print(f\"  Found at {search_range}° range: \"\n",
    "                          f\"{best_lat:.4f}°N, {best_lon:.4f}°E\")\n",
    "                    print(f\"     Temperature: {best_temp:.2f}°C, \"\n",
    "                          f\"Distance: {distance:.2f} km\")\n",
    "\n",
    "                    found_point = {\n",
    "                        'lat': best_lat,\n",
    "                        'lon': best_lon,\n",
    "                        'original_distance_km': distance,\n",
    "                        'temperature_sample': best_temp\n",
    "                    }\n",
    "                    break  # Stop expanding search radius once a point is found\n",
    "\n",
    "            if found_point:\n",
    "                replacement_coordinates[glacier] = found_point\n",
    "            else:\n",
    "                print(f\"  No 300m data found within 3° — using original coordinates\")\n",
    "                replacement_coordinates[glacier] = original_pos\n",
    "\n",
    "    return replacement_coordinates\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    replacement_locations = find_replacement_coordinates()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINAL REPLACEMENT COORDINATES:\")\n",
    "    print(\"=\" * 60)\n",
    "    for glacier, coords in replacement_locations.items():\n",
    "        if 'temperature_sample' in coords:\n",
    "            print(f\"  {glacier}: \"\n",
    "                  f\"{{'lat': {coords['lat']:.4f}, 'lon': {coords['lon']:.4f}}}  \"\n",
    "                  f\"# Temp: {coords['temperature_sample']:.2f}°C, \"\n",
    "                  f\"Dist: {coords['original_distance_km']:.1f} km\")\n",
    "        else:\n",
    "            print(f\"  {glacier}: \"\n",
    "                  f\"{{'lat': {coords['lat']:.4f}, 'lon': {coords['lon']:.4f}}}  \"\n",
    "                  f\"# Using original (no 300m data found)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5be41c0-d16f-4dac-994b-ef4480a868b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ORAS5 TEMPERATURE EXTRACTION PIPELINE\n",
      "============================================================\n",
      "\n",
      "Using replacement coordinates (from Code 1):\n",
      "  Helheim Gletsjer: 65.2358°N, -37.9326°E\n",
      "  Storebjoern: 62.9264°N, -40.8969°E\n",
      "  Daugaard-Jensen Gletsjer: 71.1908°N, -25.1324°E\n",
      "  Waltershausen Gletsjer: 72.0131°N, -22.0269°E\n",
      "\n",
      "=== QUICK VALIDATION TEST (Summer 2015) ===\n",
      "\n",
      "  Testing file 1/3: votemper_control_monthly_highres_3D_201506_OPER_v0.1.nc\n",
      "    Depth: 300.9m\n",
      "    Date: 2015-06\n",
      "    [OK] Helheim Gletsjer: 3.93°C\n",
      "    [OK] Storebjoern: 4.23°C\n",
      "    [OK] Daugaard-Jensen Gletsjer: -0.03°C\n",
      "    [OK] Waltershausen Gletsjer: 0.02°C\n",
      "\n",
      "  Testing file 2/3: votemper_control_monthly_highres_3D_201507_OPER_v0.1.nc\n",
      "    Depth: 300.9m\n",
      "    Date: 2015-07\n",
      "    [OK] Helheim Gletsjer: 4.33°C\n",
      "    [OK] Storebjoern: 4.66°C\n",
      "    [OK] Daugaard-Jensen Gletsjer: 0.01°C\n",
      "    [OK] Waltershausen Gletsjer: -0.04°C\n",
      "\n",
      "  Testing file 3/3: votemper_control_monthly_highres_3D_201508_OPER_v0.1.nc\n",
      "    Depth: 300.9m\n",
      "    Date: 2015-08\n",
      "    [OK] Helheim Gletsjer: 4.83°C\n",
      "    [OK] Storebjoern: 4.80°C\n",
      "    [OK] Daugaard-Jensen Gletsjer: 0.03°C\n",
      "    [OK] Waltershausen Gletsjer: -0.05°C\n",
      "\n",
      "============================================================\n",
      "QUICK TEST RESULTS:\n",
      "                 Glacier  Year  Month  OceanTemp Region\n",
      "        Helheim Gletsjer  2015      6   3.929709     SE\n",
      "             Storebjoern  2015      6   4.234737     SE\n",
      "Daugaard-Jensen Gletsjer  2015      6  -0.027395     NE\n",
      "  Waltershausen Gletsjer  2015      6   0.017966     NE\n",
      "        Helheim Gletsjer  2015      7   4.328588     SE\n",
      "             Storebjoern  2015      7   4.658809     SE\n",
      "Daugaard-Jensen Gletsjer  2015      7   0.010018     NE\n",
      "  Waltershausen Gletsjer  2015      7  -0.042054     NE\n",
      "        Helheim Gletsjer  2015      8   4.825997     SE\n",
      "             Storebjoern  2015      8   4.796357     SE\n",
      "Daugaard-Jensen Gletsjer  2015      8   0.031133     NE\n",
      "  Waltershausen Gletsjer  2015      8  -0.046770     NE\n",
      "\n",
      "Summer (JJA) 2015 Averages:\n",
      "  Daugaard-Jensen Gletsjer (NE): 0.00°C\n",
      "  Helheim Gletsjer (SE): 4.36°C\n",
      "  Storebjoern (SE): 4.56°C\n",
      "  Waltershausen Gletsjer (NE): -0.02°C\n",
      "\n",
      "============================================================\n",
      "PROCESSING FULL 2010–2020 DATASET...\n",
      "\n",
      "=== PROCESSING FULL DATASET 2010–2020 (JJA only) ===\n",
      "  Found 33 NetCDF files in directory\n",
      "    Processed 10 files...\n",
      "    Processed 20 files...\n",
      "    Processed 30 files...\n",
      "  Completed: 33 files processed, 132 data points collected\n",
      "\n",
      "FULL DATASET RESULTS (132 data points):\n",
      "\n",
      "Yearly Summer (JJA) Averages:\n",
      "                 Glacier  Year  OceanTemp\n",
      "Daugaard-Jensen Gletsjer  2010  -0.135370\n",
      "Daugaard-Jensen Gletsjer  2011  -0.293667\n",
      "Daugaard-Jensen Gletsjer  2012  -0.252276\n",
      "Daugaard-Jensen Gletsjer  2013  -0.089061\n",
      "Daugaard-Jensen Gletsjer  2014  -0.066131\n",
      "Daugaard-Jensen Gletsjer  2015   0.004585\n",
      "Daugaard-Jensen Gletsjer  2016   0.080413\n",
      "Daugaard-Jensen Gletsjer  2017  -0.001420\n",
      "Daugaard-Jensen Gletsjer  2018   0.194807\n",
      "Daugaard-Jensen Gletsjer  2019   0.307530\n",
      "Daugaard-Jensen Gletsjer  2020   0.158287\n",
      "        Helheim Gletsjer  2010   5.226090\n",
      "        Helheim Gletsjer  2011   4.793496\n",
      "        Helheim Gletsjer  2012   4.572702\n",
      "        Helheim Gletsjer  2013   4.824661\n",
      "        Helheim Gletsjer  2014   4.912049\n",
      "        Helheim Gletsjer  2015   4.361432\n",
      "        Helheim Gletsjer  2016   4.291023\n",
      "        Helheim Gletsjer  2017   4.645880\n",
      "        Helheim Gletsjer  2018   4.304144\n",
      "        Helheim Gletsjer  2019   4.914913\n",
      "        Helheim Gletsjer  2020   4.410433\n",
      "             Storebjoern  2010   5.269625\n",
      "             Storebjoern  2011   4.876580\n",
      "             Storebjoern  2012   5.046650\n",
      "             Storebjoern  2013   4.932363\n",
      "             Storebjoern  2014   4.847922\n",
      "             Storebjoern  2015   4.563301\n",
      "             Storebjoern  2016   4.587400\n",
      "             Storebjoern  2017   4.732667\n",
      "             Storebjoern  2018   4.630626\n",
      "             Storebjoern  2019   4.991153\n",
      "             Storebjoern  2020   4.840081\n",
      "  Waltershausen Gletsjer  2010   0.004347\n",
      "  Waltershausen Gletsjer  2011  -0.344783\n",
      "  Waltershausen Gletsjer  2012  -0.078406\n",
      "  Waltershausen Gletsjer  2013   0.249684\n",
      "  Waltershausen Gletsjer  2014   0.230553\n",
      "  Waltershausen Gletsjer  2015  -0.023619\n",
      "  Waltershausen Gletsjer  2016  -0.176646\n",
      "  Waltershausen Gletsjer  2017   0.344036\n",
      "  Waltershausen Gletsjer  2018   0.594068\n",
      "  Waltershausen Gletsjer  2019   0.501623\n",
      "  Waltershausen Gletsjer  2020   0.003925\n",
      "\n",
      "SE Region: mean = 4.75°C, min = 3.78°C, max = 5.70°C\n",
      "\n",
      "NE Region: mean = 0.06°C, min = -0.35°C, max = 0.60°C\n",
      "\n",
      "Data saved to: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/glacier_temperature_300m_2010_2020.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 1, Code 2: ORAS5 Ocean Temperature Extraction Pipeline\n",
    "# =============================================================================\n",
    "# This script extracts monthly ocean potential temperature at 300m depth\n",
    "# from ORAS5 reanalysis (CDS, 2021) for four Greenland outlet glaciers\n",
    "# over the period 2010–2020, filtering for summer months (June–July–August,\n",
    "# JJA).\n",
    "#\n",
    "# The extraction uses \"replacement coordinates\" identified in Code 1,\n",
    "# which represent the nearest valid ocean grid points to each glacier\n",
    "# terminus. The pipeline processes 33 monthly NetCDF files (3 JJA months\n",
    "# × 11 years) and produces 132 data points (4 glaciers × 33 months).\n",
    "#\n",
    "# Grid point matching uses Euclidean distance minimisation on the ORAS5\n",
    "# curvilinear grid (nav_lat, nav_lon), consistent with the approach in\n",
    "# Sections 4 and 5.\n",
    "#\n",
    "# Output: glacier_temperature_300m_2010_2020.csv\n",
    "# =============================================================================\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Configuration\n",
    "base_dir = \"/Users/kyle/Documents/dissertation/ORAS5/votemper\"\n",
    "output_folder = \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Final replacement coordinates from Code 1 (nearest valid ocean points at 300m)\n",
    "replacement_locations = {\n",
    "    \"Helheim Gletsjer\":         {\"lat\": 65.2358, \"lon\": -37.9326},   \n",
    "    \"Storebjoern\":              {\"lat\": 62.9264, \"lon\": -40.8969},   \n",
    "    \"Daugaard-Jensen Gletsjer\": {\"lat\": 71.1908, \"lon\": -25.1324},   \n",
    "    \"Waltershausen Gletsjer\":   {\"lat\": 72.0131, \"lon\": -22.0269}    \n",
    "}\n",
    "\n",
    "# Regional classification divided at 69°N (Seale et al., 2011)\n",
    "region_tags = {\n",
    "    \"Helheim Gletsjer\": \"SE\",\n",
    "    \"Storebjoern\": \"SE\",\n",
    "    \"Daugaard-Jensen Gletsjer\": \"NE\",\n",
    "    \"Waltershausen Gletsjer\": \"NE\"\n",
    "}\n",
    "\n",
    "\n",
    "def extract_month_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Extract year and month from an ORAS5 NetCDF filename.\n",
    "\n",
    "    Expected pattern: votemper_control_monthly_highres_3D_YYYYMM_*.nc\n",
    "    The 6th underscore-delimited token contains the YYYYMM string.\n",
    "\n",
    "    Args:\n",
    "        filename (str): NetCDF filename.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (year, month) as integers.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If YYYYMM cannot be parsed from the filename.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Primary method: split by underscore, 6th element is YYYYMM\n",
    "        year_month = filename.split('_')[5]\n",
    "        month = int(year_month[4:6])\n",
    "        year = int(year_month[:4])\n",
    "        return year, month\n",
    "    except (IndexError, ValueError):\n",
    "        # Fallback: regex search for 6-digit date string\n",
    "        import re\n",
    "        match = re.search(r'_(\\d{6})_', filename)\n",
    "        if match:\n",
    "            year_month = match.group(1)\n",
    "            return int(year_month[:4]), int(year_month[4:6])\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot extract date from filename: {filename}\")\n",
    "\n",
    "\n",
    "def quick_test_with_coordinates(coordinates_dict):\n",
    "    \"\"\"\n",
    "    Quick validation test using three summer 2015 files.\n",
    "\n",
    "    Extracts 300m-depth temperature for each glacier from June, July,\n",
    "    and August 2015 to verify that the replacement coordinates yield\n",
    "    valid (non-NaN) data at the expected depth.\n",
    "\n",
    "    Args:\n",
    "        coordinates_dict (dict): Glacier coordinates to test.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Extracted temperature data for validation.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== QUICK VALIDATION TEST (Summer 2015) ===\")\n",
    "\n",
    "    test_files = [\n",
    "        \"votemper_control_monthly_highres_3D_201506_OPER_v0.1.nc\",\n",
    "        \"votemper_control_monthly_highres_3D_201507_OPER_v0.1.nc\",\n",
    "        \"votemper_control_monthly_highres_3D_201508_OPER_v0.1.nc\",\n",
    "    ]\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for i, file in enumerate(test_files):\n",
    "        print(f\"\\n  Testing file {i+1}/3: {file}\")\n",
    "        file_path = os.path.join(base_dir, file)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"    File not found: {file}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with xr.open_dataset(file_path) as ds:\n",
    "                # Find depth index closest to 300m\n",
    "                depth_idx = np.abs(ds.deptht.values - 300).argmin()\n",
    "                actual_depth = ds.deptht.values[depth_idx]\n",
    "                print(f\"    Depth: {actual_depth:.1f}m\")\n",
    "\n",
    "                # Extract year and month from filename\n",
    "                year, month = extract_month_from_filename(file)\n",
    "                print(f\"    Date: {year}-{month:02d}\")\n",
    "\n",
    "                for glacier, pos in coordinates_dict.items():\n",
    "                    lat, lon = pos['lat'], pos['lon']\n",
    "\n",
    "                    # Find nearest grid point via Euclidean distance\n",
    "                    dist_matrix = (ds.nav_lon - lon)**2 + (ds.nav_lat - lat)**2\n",
    "                    y_idx, x_idx = np.unravel_index(\n",
    "                        np.argmin(dist_matrix.values), dist_matrix.shape\n",
    "                    )\n",
    "\n",
    "                    # Extract temperature at 300m\n",
    "                    temp = ds.votemper.isel(\n",
    "                        time_counter=0, deptht=depth_idx, y=y_idx, x=x_idx\n",
    "                    ).values.item()\n",
    "\n",
    "                    status = \"OK\" if not np.isnan(temp) else \"NaN\"\n",
    "                    print(f\"    [{status}] {glacier}: {temp:.2f}°C\")\n",
    "\n",
    "                    if not np.isnan(temp):\n",
    "                        all_data.append({\n",
    "                            'Glacier': glacier,\n",
    "                            'Year': year,\n",
    "                            'Month': month,\n",
    "                            'OceanTemp': temp,\n",
    "                            'Region': region_tags[glacier]\n",
    "                        })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    Error: {e}\")\n",
    "\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "def process_full_dataset(coordinates_dict, start_year=2010, end_year=2020):\n",
    "    \"\"\"\n",
    "    Extract summer (JJA) ocean temperature at 300m depth for all glaciers\n",
    "    across the full study period (2010–2020).\n",
    "\n",
    "    Iterates over all NetCDF files in the data directory, filters for\n",
    "    June–July–August within the specified year range, and extracts\n",
    "    temperature at each glacier's replacement ocean grid point.\n",
    "\n",
    "    Args:\n",
    "        coordinates_dict (dict): Glacier replacement coordinates.\n",
    "        start_year (int): First year of the study period.\n",
    "        end_year (int): Last year of the study period.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Columns — Glacier, Year, Month, OceanTemp, Region.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== PROCESSING FULL DATASET {start_year}–{end_year} (JJA only) ===\")\n",
    "\n",
    "    all_data = []\n",
    "    processed_files = 0\n",
    "\n",
    "    # List all NetCDF files in the data directory\n",
    "    all_files = [f for f in os.listdir(base_dir) if f.endswith('.nc')]\n",
    "    print(f\"  Found {len(all_files)} NetCDF files in directory\")\n",
    "\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            # Extract date from filename\n",
    "            year, month = extract_month_from_filename(file)\n",
    "\n",
    "            # Filter: summer months (JJA) within the study period only\n",
    "            if month not in [6, 7, 8] or year < start_year or year > end_year:\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(base_dir, file)\n",
    "\n",
    "            with xr.open_dataset(file_path) as ds:\n",
    "                # Find depth index closest to 300m\n",
    "                depth_idx = np.abs(ds.deptht.values - 300).argmin()\n",
    "\n",
    "                for glacier, pos in coordinates_dict.items():\n",
    "                    lat, lon = pos['lat'], pos['lon']\n",
    "\n",
    "                    # Find nearest grid point via Euclidean distance\n",
    "                    dist_matrix = (ds.nav_lon - lon)**2 + (ds.nav_lat - lat)**2\n",
    "                    y_idx, x_idx = np.unravel_index(\n",
    "                        np.argmin(dist_matrix.values), dist_matrix.shape\n",
    "                    )\n",
    "\n",
    "                    # Extract temperature at 300m\n",
    "                    temp = ds.votemper.isel(\n",
    "                        time_counter=0, deptht=depth_idx, y=y_idx, x=x_idx\n",
    "                    ).values.item()\n",
    "\n",
    "                    if not np.isnan(temp):\n",
    "                        all_data.append({\n",
    "                            'Glacier': glacier,\n",
    "                            'Year': year,\n",
    "                            'Month': month,\n",
    "                            'OceanTemp': temp,\n",
    "                            'Region': region_tags[glacier]\n",
    "                        })\n",
    "\n",
    "                processed_files += 1\n",
    "                if processed_files % 10 == 0:\n",
    "                    print(f\"    Processed {processed_files} files...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    Error with {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"  Completed: {processed_files} files processed, \"\n",
    "          f\"{len(all_data)} data points collected\")\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ORAS5 TEMPERATURE EXTRACTION PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nUsing replacement coordinates (from Code 1):\")\n",
    "    for glacier, coords in replacement_locations.items():\n",
    "        print(f\"  {glacier}: {coords['lat']:.4f}°N, {coords['lon']:.4f}°E\")\n",
    "\n",
    "    # Step 1: Quick validation test with summer 2015 data\n",
    "    test_results = quick_test_with_coordinates(replacement_locations)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"QUICK TEST RESULTS:\")\n",
    "    if not test_results.empty:\n",
    "        print(test_results.to_string(index=False))\n",
    "\n",
    "        # Summer 2015 averages per glacier\n",
    "        summer_avg = test_results.groupby(['Glacier', 'Region'])['OceanTemp'].mean()\n",
    "        print(f\"\\nSummer (JJA) 2015 Averages:\")\n",
    "        for (glacier, region), temp in summer_avg.items():\n",
    "            print(f\"  {glacier} ({region}): {temp:.2f}°C\")\n",
    "    else:\n",
    "        print(\"  No data collected — check file paths and coordinates\")\n",
    "\n",
    "    # Step 2: Process full 2010–2020 dataset\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROCESSING FULL 2010–2020 DATASET...\")\n",
    "    full_results = process_full_dataset(replacement_locations)\n",
    "\n",
    "    if not full_results.empty:\n",
    "        print(f\"\\nFULL DATASET RESULTS ({len(full_results)} data points):\")\n",
    "\n",
    "        # Yearly summer (JJA) averages\n",
    "        yearly_avg = full_results.groupby(\n",
    "            ['Glacier', 'Year']\n",
    "        )['OceanTemp'].mean().reset_index()\n",
    "        print(\"\\nYearly Summer (JJA) Averages:\")\n",
    "        print(yearly_avg.to_string(index=False))\n",
    "\n",
    "        # Regional summary statistics\n",
    "        for region in ['SE', 'NE']:\n",
    "            region_temps = full_results[full_results['Region'] == region]['OceanTemp']\n",
    "            print(f\"\\n{region} Region: mean = {region_temps.mean():.2f}°C, \"\n",
    "                  f\"min = {region_temps.min():.2f}°C, \"\n",
    "                  f\"max = {region_temps.max():.2f}°C\")\n",
    "\n",
    "        # Save to CSV\n",
    "        csv_path = os.path.join(output_folder, \"glacier_temperature_300m_2010_2020.csv\")\n",
    "        full_results.to_csv(csv_path, index=False)\n",
    "        print(f\"\\nData saved to: {csv_path}\")\n",
    "    else:\n",
    "        print(\"  No data collected — check file paths and coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a099b2-5377-45fd-9c8d-993dafb74a68",
   "metadata": {},
   "source": [
    "## Section 2: Advanced Glacier-Ocean Visualization System with Multi-Source Geospatial Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1265f61-05ef-45e8-846e-5b022af41b46",
   "metadata": {},
   "source": [
    "This sophisticated geospatial visualization system integrates Cartopy (v0.24.1) for orthographic projections and map elements, Rasterio (v1.4.3) for processing IBCAO Version 5.0 bathymetric data (Jakobsson et al., 2024) at native 100m resolution (2024 release), and Geopy (v2.4.1) for precise geodesic distance calculations between glacier termini and ocean sampling locations. The implementation creates a comprehensive visualization framework that combines high-resolution bathymetric data (100m resolution GeoTIFF) with satellite imagery through a carefully designed dual-map approach, incorporating fallback synthetic bathymetry generation for missing data scenarios. The orthographic overview map utilizes Cartopy's advanced coordinate reference system (CRS) transformations to display glacier-ocean pairs within their regional context, while detailed maps employ Google Terrain tiles (Google Maps API, 2025) through Cartopy's image tile interface for localized examination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab984da3-9b4e-47bc-98e5-c265237a3f27",
   "metadata": {},
   "source": [
    "The system implements a rigorous coordinate transformation pipeline using Rasterio's warp functionality to convert between WGS84 (EPSG:4326) and IBCAO's native CRS (EPSG:3996), ensuring accurate positioning of bathymetric data. Geopy's geodesic function calculates great-circle distances between glacier termini (marked with 14pt red circles) and their corresponding ocean points (12pt blue X markers), with connection lines (1.8pt purple dashes) dynamically labeled using Cartopy's advanced text positioning system. The bathymetric visualization employs a specialized processing chain that includes data windowing, coordinate transformation, and depth-based masking (-500m to 0m range) to optimize both performance and visual clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfbf7e0-c89f-4302-b1cc-4ef2cca28cb2",
   "metadata": {},
   "source": [
    "For regional context, the visualization incorporates multiple Cartopy features including 50m-resolution coastline vectors, land masks with custom coloring (#f0e6dc), and a 69°N reference line marking the NE/SE boundary as established in Seale et al. (2011). The technical implementation demonstrates tight integration between these libraries - Rasterio handles the bathymetric data extraction and CRS transformations, Cartopy manages the map projections and visual elements, while Geopy provides the essential spatial calculations that connect the terrestrial and marine components of the study. Outputs are generated as publication-ready 300DPI images with print-optimized color schemes, maintaining consistent styling across both overview (14×12\") and detailed (12×10\") maps through shared color schemes and annotation styles. All maps contextualize the summer (JJA) study period by displaying glacier-ocean point pairs used in subsequent seasonal analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5f2ac8-ba05-4a92-b052-740dab9cd4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cartopy in /opt/anaconda3/lib/python3.11/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/lib/python3.11/site-packages (from cartopy) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /opt/anaconda3/lib/python3.11/site-packages (from cartopy) (3.8.0)\n",
      "Requirement already satisfied: shapely>=1.8 in /opt/anaconda3/lib/python3.11/site-packages (from cartopy) (2.1.1)\n",
      "Requirement already satisfied: packaging>=21 in /opt/anaconda3/lib/python3.11/site-packages (from cartopy) (23.1)\n",
      "Requirement already satisfied: pyshp>=2.3 in /opt/anaconda3/lib/python3.11/site-packages (from cartopy) (2.3.1)\n",
      "Requirement already satisfied: pyproj>=3.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from cartopy) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.6->cartopy) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.6->cartopy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.6->cartopy) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.6->cartopy) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.6->cartopy) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.6->cartopy) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.6->cartopy) (2.8.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from pyproj>=3.3.1->cartopy) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.6->cartopy) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "942a72c8-84c7-49ed-b8ea-a391dc96d461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.1\n"
     ]
    }
   ],
   "source": [
    "import cartopy\n",
    "print(cartopy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e228d59-ec67-421e-aa2e-86d037ff38b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in /opt/anaconda3/lib/python3.11/site-packages (2.4.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /opt/anaconda3/lib/python3.11/site-packages (from geopy) (2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1faf6fdc-2854-4300-9dd0-5b128f1e0b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import geopy\n",
    "print(geopy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08b78c6e-fc1c-4cdc-bf4e-968731d561e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasterio in /opt/anaconda3/lib/python3.11/site-packages (1.4.3)\n",
      "Requirement already satisfied: affine in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (2024.2.2)\n",
      "Requirement already satisfied: click>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.24 in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (1.26.4)\n",
      "Requirement already satisfied: click-plugins in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (1.1.1.2)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e434c210-de26-4958-9360-1eb4696895fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.3\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "print(rasterio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98f77f67-f0f6-4272-ae24-9574ec9159df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GEOSPATIAL VISUALISATION PIPELINE\n",
      "============================================================\n",
      "\n",
      "Creating Greenland Overview Map...\n",
      "=== Bathymetry Data Loading ===\n",
      "  CRS: EPSG:3996\n",
      "  Greenland overview saved: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/greenland_overview_map.png\n",
      "\n",
      "Creating Individual Glacier Detail Maps...\n",
      "  Detail map saved: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/Helheim_Gletsjer_Comparison.png\n",
      "  Detail map saved: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/Storebjoern_Comparison.png\n",
      "  Detail map saved: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/Daugaard-Jensen_Gletsjer_Comparison.png\n",
      "  Detail map saved: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/Waltershausen_Gletsjer_Comparison.png\n",
      "\n",
      "============================================================\n",
      "All maps generated successfully.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 2: Geospatial Visualisation — Greenland Overview and Glacier Maps\n",
    "# =============================================================================\n",
    "# This script generates two types of maps:\n",
    "#\n",
    "#   (1) Greenland Overview Map — Orthographic projection centred on the study\n",
    "#       area, with IBCAO v5.0 bathymetry (Jakobsson et al., 2024) clipped to\n",
    "#       0–500m depth. Original glacier terminus locations (red circles) and\n",
    "#       replacement ocean data points (blue crosses) are connected by dashed\n",
    "#       lines annotated with geodesic distances (km). A 69°N reference line\n",
    "#       divides the NE/SE regions (Seale et al., 2011).\n",
    "#\n",
    "#   (2) Individual Glacier Detail Maps — Satellite imagery (Google Tiles) for\n",
    "#       each glacier, showing original vs. replacement coordinates with DMS\n",
    "#       annotations and distance labels.\n",
    "#\n",
    "# Dependencies: cartopy (map projections), rasterio (IBCAO GeoTIFF),\n",
    "#               geopy (geodesic distances)\n",
    "#\n",
    "# Data sources:\n",
    "#   - IBCAO v5.0 bathymetry: Jakobsson et al. (2024), 100m resolution\n",
    "#   - Glacier coordinates: Google Earth (2025)\n",
    "#   - Satellite tiles: Google Maps API (2025)\n",
    "# =============================================================================\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import offset_copy\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "import rasterio\n",
    "from rasterio.warp import transform as rio_transform\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Glacier Coordinate Definitions\n",
    "# =====================================================================\n",
    "\n",
    "# Original glacier terminus locations (Source: Google Earth, 2025)\n",
    "original_locations = {\n",
    "    \"Helheim Gletsjer\": {\n",
    "        \"lat\": 66 + 21/60,               # 66°21'00\"N\n",
    "        \"lon\": -(38 + 12/60),             # 38°12'00\"W\n",
    "        \"region\": \"SE\"\n",
    "    },\n",
    "    \"Storebjoern\": {\n",
    "        \"lat\": 63 + 43/60,               # 63°43'00\"N\n",
    "        \"lon\": -(41 + 38/60 + 59/3600),   # 41°38'59\"W\n",
    "        \"region\": \"SE\"\n",
    "    },\n",
    "    \"Daugaard-Jensen Gletsjer\": {\n",
    "        \"lat\": 71 + 52/60 + 14/3600,      # 71°52'14\"N\n",
    "        \"lon\": -(28 + 42/60 + 4/3600),    # 28°42'04\"W\n",
    "        \"region\": \"NE\"\n",
    "    },\n",
    "    \"Waltershausen Gletsjer\": {\n",
    "        \"lat\": 73 + 54/60,               # 73°54'00\"N\n",
    "        \"lon\": -(24 + 25/60),             # 24°25'00\"W\n",
    "        \"region\": \"NE\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Replacement coordinates: nearest valid ORAS5 ocean grid points at 300m\n",
    "# depth, identified by Section 1 Code 1\n",
    "replacement_locations = {\n",
    "    \"Helheim Gletsjer\":         {\"lat\": 65.2358, \"lon\": -37.9326},   \n",
    "    \"Storebjoern\":              {\"lat\": 62.9264, \"lon\": -40.8969},   \n",
    "    \"Daugaard-Jensen Gletsjer\": {\"lat\": 71.1908, \"lon\": -25.1324},   \n",
    "    \"Waltershausen Gletsjer\":   {\"lat\": 72.0131, \"lon\": -22.0269}    \n",
    "}\n",
    "\n",
    "# Output directory\n",
    "output_folder = \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Utility Functions\n",
    "# =====================================================================\n",
    "\n",
    "def decimal_to_dms(coord, is_lat):\n",
    "    \"\"\"\n",
    "    Convert decimal degree coordinate to degrees-minutes-seconds string.\n",
    "\n",
    "    Args:\n",
    "        coord (float): Decimal degree value.\n",
    "        is_lat (bool): True for latitude (N/S), False for longitude (E/W).\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted DMS string, e.g. '66°21'0.0\"N'.\n",
    "    \"\"\"\n",
    "    abs_coord = abs(coord)\n",
    "    degrees = int(abs_coord)\n",
    "    remaining = (abs_coord - degrees) * 60\n",
    "    minutes = int(remaining)\n",
    "    seconds = round((remaining - minutes) * 60, 1)\n",
    "\n",
    "    # Handle rounding overflow\n",
    "    if seconds >= 60:\n",
    "        seconds = 0\n",
    "        minutes += 1\n",
    "    if minutes >= 60:\n",
    "        minutes = 0\n",
    "        degrees += 1\n",
    "\n",
    "    if is_lat:\n",
    "        direction = \"N\" if coord >= 0 else \"S\"\n",
    "    else:\n",
    "        direction = \"E\" if coord >= 0 else \"W\"\n",
    "\n",
    "    return f\"{degrees}°{minutes}'{seconds}\\\"{direction}\"\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Figure 1: Greenland Overview Map with IBCAO Bathymetry\n",
    "# =====================================================================\n",
    "\n",
    "def create_greenland_map():\n",
    "    \"\"\"\n",
    "    Create a Greenland overview map showing original glacier locations,\n",
    "    replacement ocean data points, and IBCAO v5.0 bathymetry (0–500m).\n",
    "\n",
    "    The map uses an Orthographic projection centred on the study area\n",
    "    (-40°E, 72°N). A 69°N reference line marks the NE/SE regional\n",
    "    boundary (Seale et al., 2011). Connection lines between original\n",
    "    and replacement coordinates are annotated with geodesic distances.\n",
    "\n",
    "    Returns:\n",
    "        str: File path of the saved figure.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    proj = ccrs.Orthographic(central_longitude=-40, central_latitude=72)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=proj)\n",
    "\n",
    "    # Map display extent (visible area)\n",
    "    display_extent = [-45, -25, 62, 74.5]\n",
    "    ax.set_extent(display_extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Data loading extent (wider than display to avoid edge artefacts)\n",
    "    data_extent = [-43, -5, 50, 75]\n",
    "\n",
    "    bathymetry_path = \"/Users/kyle/Documents/dissertation/ibcao-5.0/ibcao-2024-100m-20240701-depth.tiff\"\n",
    "\n",
    "    try:\n",
    "        with rasterio.open(bathymetry_path) as src:\n",
    "            print(\"=== Bathymetry Data Loading ===\")\n",
    "            print(f\"  CRS: {src.crs}\")\n",
    "\n",
    "            # Coordinate transformation: WGS84 → IBCAO CRS (EPSG:3996)\n",
    "            src_crs = 'EPSG:4326'\n",
    "            dst_crs = src.crs\n",
    "\n",
    "            xmin, ymin = rio_transform(\n",
    "                src_crs, dst_crs,\n",
    "                [data_extent[0]], [data_extent[2]]\n",
    "            )\n",
    "            xmax, ymax = rio_transform(\n",
    "                src_crs, dst_crs,\n",
    "                [data_extent[1]], [data_extent[3]]\n",
    "            )\n",
    "\n",
    "            # Calculate pixel window from projected coordinates\n",
    "            transform = src.transform\n",
    "            inv_transform = ~transform\n",
    "\n",
    "            left, bottom = inv_transform * (xmin[0], ymin[0])\n",
    "            right, top = inv_transform * (xmax[0], ymax[0])\n",
    "\n",
    "            col_start = max(0, int(left))\n",
    "            row_start = max(0, int(top))\n",
    "            col_stop = min(src.width, int(right))\n",
    "            row_stop = min(src.height, int(bottom))\n",
    "\n",
    "            width = col_stop - col_start\n",
    "            height = row_stop - row_start\n",
    "\n",
    "            # Read bathymetry data within window\n",
    "            window = rasterio.windows.Window(\n",
    "                col_start, row_start, width, height)\n",
    "            bathymetry = src.read(1, window=window)\n",
    "            window_transform = src.window_transform(window)\n",
    "\n",
    "            # Build coordinate grids in IBCAO CRS\n",
    "            rows, cols = bathymetry.shape\n",
    "            x_coords = np.linspace(\n",
    "                window_transform[2],\n",
    "                window_transform[2] + window_transform[0] * cols,\n",
    "                cols\n",
    "            )\n",
    "            y_coords = np.linspace(\n",
    "                window_transform[5],\n",
    "                window_transform[5] + window_transform[4] * rows,\n",
    "                rows\n",
    "            )\n",
    "            xx, yy = np.meshgrid(x_coords, y_coords)\n",
    "\n",
    "            # Transform IBCAO CRS → WGS84 for plotting\n",
    "            lon, lat = rio_transform(\n",
    "                dst_crs, src_crs,\n",
    "                np.array(xx).flatten(),\n",
    "                np.array(yy).flatten()\n",
    "            )\n",
    "            lon = np.array(lon).reshape(xx.shape)\n",
    "            lat = np.array(lat).reshape(yy.shape)\n",
    "\n",
    "            # Mask land (>=0) and values outside data extent\n",
    "            bathymetry = np.ma.masked_where(\n",
    "                (bathymetry >= 0) |\n",
    "                (lon < data_extent[0]) | (lon > data_extent[1]) |\n",
    "                (lat < data_extent[2]) | (lat > data_extent[3]),\n",
    "                bathymetry\n",
    "            )\n",
    "            # Clip to 0–500m depth range (relevant for glacier-ocean interaction)\n",
    "            bathymetry = np.clip(bathymetry, -500, 0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Bathymetry loading failed: {e}\")\n",
    "        print(\"  Using synthetic fallback data\")\n",
    "        lon = np.linspace(data_extent[0], data_extent[1], 1000)\n",
    "        lat = np.linspace(data_extent[2], data_extent[3], 1000)\n",
    "        lon, lat = np.meshgrid(lon, lat)\n",
    "        bathymetry = -1000 * np.exp(-((lon + 35)**2 + (lat - 68)**2) / 50)\n",
    "        bathymetry = np.clip(bathymetry, -1000, 0)\n",
    "\n",
    "    # --- Bathymetry contour fill ---\n",
    "    levels = np.linspace(-500, 0, 11)\n",
    "    cs = ax.contourf(lon, lat, bathymetry, levels=levels,\n",
    "                     cmap='Blues_r', extend='both',\n",
    "                     transform=ccrs.PlateCarree(), alpha=0.8)\n",
    "\n",
    "    # --- Base map features ---\n",
    "    ax.add_feature(cfeature.LAND, facecolor='#f0e6dc', zorder=2)\n",
    "    ax.add_feature(cfeature.COASTLINE, edgecolor='#5c5c5c', zorder=3)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=1.2, alpha=0.7)\n",
    "    ax.gridlines(draw_labels=True, linewidth=0.7, color='gray',\n",
    "                 alpha=0.6, linestyle='--')\n",
    "    ax.add_feature(cfeature.LAND.with_scale('50m'),\n",
    "                   facecolor='#f0e6dc', edgecolor='none', zorder=1)\n",
    "\n",
    "    # Colour bar\n",
    "    cbar = plt.colorbar(cs, ax=ax, shrink=0.6)\n",
    "    cbar.set_label('Ocean Depth (m)', fontsize=12)\n",
    "\n",
    "    # --- Glacier markers ---\n",
    "    # Original locations (red circles)\n",
    "    for glacier, loc in original_locations.items():\n",
    "        ax.plot(loc[\"lon\"], loc[\"lat\"],\n",
    "                marker='o', markersize=14, color='red',\n",
    "                markeredgecolor='black',\n",
    "                transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Replacement locations (blue crosses)\n",
    "    for glacier, loc in replacement_locations.items():\n",
    "        ax.plot(loc[\"lon\"], loc[\"lat\"],\n",
    "                marker='X', markersize=12, color='blue',\n",
    "                markeredgecolor='black',\n",
    "                transform=ccrs.PlateCarree())\n",
    "\n",
    "    # --- Connection lines with distance labels ---\n",
    "    for glacier in original_locations:\n",
    "        orig = original_locations[glacier]\n",
    "        repl = replacement_locations[glacier]\n",
    "\n",
    "        ax.plot([orig[\"lon\"], repl[\"lon\"]], [orig[\"lat\"], repl[\"lat\"]],\n",
    "                color='purple', linestyle='--', linewidth=1.8, alpha=0.8,\n",
    "                transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Geodesic distance\n",
    "        distance = geodesic(\n",
    "            (orig[\"lat\"], orig[\"lon\"]),\n",
    "            (repl[\"lat\"], repl[\"lon\"])\n",
    "        ).km\n",
    "        mid_lon = (orig[\"lon\"] + repl[\"lon\"]) / 2\n",
    "        mid_lat = (orig[\"lat\"] + repl[\"lat\"]) / 2\n",
    "\n",
    "        # Per-glacier label positioning to avoid overlap\n",
    "        if glacier == \"Waltershausen Gletsjer\":\n",
    "            text_transform = offset_copy(\n",
    "                ccrs.Geodetic()._as_mpl_transform(ax),\n",
    "                units='dots', x=-40, y=-60)\n",
    "            ha = 'right'\n",
    "        elif glacier == \"Daugaard-Jensen Gletsjer\":\n",
    "            text_transform = offset_copy(\n",
    "                ccrs.Geodetic()._as_mpl_transform(ax),\n",
    "                units='dots', x=-80, y=-40)\n",
    "            ha = 'right'\n",
    "        else:\n",
    "            text_transform = offset_copy(\n",
    "                ccrs.Geodetic()._as_mpl_transform(ax),\n",
    "                units='dots', x=50, y=0)\n",
    "            ha = 'left'\n",
    "\n",
    "        ax.text(mid_lon, mid_lat, f\"{distance:.1f} km\",\n",
    "                verticalalignment='center',\n",
    "                horizontalalignment=ha,\n",
    "                transform=text_transform,\n",
    "                bbox=dict(facecolor='white', alpha=0.8, boxstyle='round'),\n",
    "                fontsize=10, weight='bold')\n",
    "\n",
    "    # --- Glacier name labels ---\n",
    "    for glacier, loc in original_locations.items():\n",
    "        geodetic_transform = ccrs.Geodetic()._as_mpl_transform(ax)\n",
    "\n",
    "        if glacier in (\"Waltershausen Gletsjer\", \"Daugaard-Jensen Gletsjer\"):\n",
    "            text_transform = offset_copy(\n",
    "                geodetic_transform, units='dots', x=-60, y=0)\n",
    "            ha = 'right'\n",
    "        else:\n",
    "            # Helheim and Storebjørn: label above marker\n",
    "            text_transform = offset_copy(\n",
    "                geodetic_transform, units='dots', x=0, y=80)\n",
    "            ha = 'center'\n",
    "\n",
    "        ax.text(loc[\"lon\"], loc[\"lat\"], glacier,\n",
    "                verticalalignment='center',\n",
    "                horizontalalignment=ha,\n",
    "                transform=text_transform,\n",
    "                bbox=dict(facecolor='white', alpha=0.8, boxstyle='round'),\n",
    "                fontsize=11, weight='bold')\n",
    "\n",
    "    # --- 69°N regional boundary line (Seale et al., 2011) ---\n",
    "    lat_69 = 69.0\n",
    "    lons = np.linspace(-75, -10, 100)\n",
    "    lats = np.full_like(lons, lat_69)\n",
    "    ax.plot(lons, lats, color='black', linestyle='--', linewidth=1.5,\n",
    "            transform=ccrs.PlateCarree(), alpha=0.7)\n",
    "\n",
    "    ax.text(-30, lat_69 - 0.5,\n",
    "            \"69°N Reference Latitude\\n(Seale et al., 2011)\",\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            bbox=dict(facecolor='white', alpha=0.7, boxstyle='round'),\n",
    "            fontsize=10, weight='bold')\n",
    "\n",
    "    # NE/SE region labels\n",
    "    label_params = {\n",
    "        'transform': ccrs.PlateCarree(),\n",
    "        'fontsize': 14,\n",
    "        'weight': 'bold',\n",
    "        'bbox': dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.3')\n",
    "    }\n",
    "    ax.text(-45, 70, \"NORTHEAST (NE)\", color='darkred', **label_params)\n",
    "    ax.text(-45, 68, \"SOUTHEAST (SE)\", color='darkblue', **label_params)\n",
    "\n",
    "    # --- Legend ---\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='red',\n",
    "               markersize=12, markeredgecolor='black',\n",
    "               label='Original Glacier Location'),\n",
    "        Line2D([0], [0], marker='X', color='w', markerfacecolor='blue',\n",
    "               markersize=12, markeredgecolor='black',\n",
    "               label='Ocean Data Point (300m depth)'),\n",
    "        Line2D([0], [0], color='purple', linestyle='--', lw=2,\n",
    "               label='Connection')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "\n",
    "    plt.title(\"Greenland Glacier Locations with Ocean Data Points\",\n",
    "              fontsize=18, pad=25, weight='bold')\n",
    "\n",
    "    save_path = os.path.join(output_folder, \"greenland_overview_map.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return save_path\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Figures 2–5: Individual Glacier Detail Maps (Satellite Imagery)\n",
    "# =====================================================================\n",
    "\n",
    "def create_glacier_detail_maps():\n",
    "    \"\"\"\n",
    "    Create satellite-view detail maps for each glacier, showing the\n",
    "    original terminus location vs. the replacement ocean data point.\n",
    "\n",
    "    Each map includes:\n",
    "    - Google satellite imagery at appropriate zoom level\n",
    "    - Red circle (original) and blue cross (replacement) markers\n",
    "    - Purple dashed connection line with distance annotation\n",
    "    - DMS coordinate info box\n",
    "\n",
    "    Returns:\n",
    "        list: File paths of saved figures.\n",
    "    \"\"\"\n",
    "    google_terrain = cimgt.GoogleTiles(style=\"satellite\")\n",
    "    saved_paths = []\n",
    "\n",
    "    for glacier in original_locations:\n",
    "        orig_loc = original_locations[glacier]\n",
    "        repl_loc = replacement_locations[glacier]\n",
    "\n",
    "        # Map extent: encompass both coordinates with padding\n",
    "        all_lats = [orig_loc[\"lat\"], repl_loc[\"lat\"]]\n",
    "        all_lons = [orig_loc[\"lon\"], repl_loc[\"lon\"]]\n",
    "\n",
    "        lat_padding = max(0.8, 0.3 * abs(orig_loc[\"lat\"] - repl_loc[\"lat\"]))\n",
    "        lon_padding = max(1.2, 0.3 * abs(orig_loc[\"lon\"] - repl_loc[\"lon\"]))\n",
    "\n",
    "        extent = [\n",
    "            min(all_lons) - lon_padding,\n",
    "            max(all_lons) + lon_padding,\n",
    "            min(all_lats) - lat_padding,\n",
    "            max(all_lats) + lat_padding\n",
    "        ]\n",
    "\n",
    "        # Create map with satellite imagery\n",
    "        fig = plt.figure(figsize=(12, 10))\n",
    "        ax = fig.add_subplot(1, 1, 1, projection=google_terrain.crs)\n",
    "        ax.set_extent(extent, crs=ccrs.Geodetic())\n",
    "        ax.add_image(google_terrain, 10)\n",
    "\n",
    "        # Original location (red circle)\n",
    "        ax.plot(orig_loc[\"lon\"], orig_loc[\"lat\"],\n",
    "                marker='o', color='red', markersize=18,\n",
    "                markeredgecolor='black', alpha=0.9,\n",
    "                transform=ccrs.Geodetic())\n",
    "\n",
    "        # Replacement location (blue cross)\n",
    "        ax.plot(repl_loc[\"lon\"], repl_loc[\"lat\"],\n",
    "                marker='X', color='blue', markersize=16,\n",
    "                markeredgecolor='black', alpha=0.9,\n",
    "                transform=ccrs.Geodetic())\n",
    "\n",
    "        # Connection line\n",
    "        ax.plot([orig_loc[\"lon\"], repl_loc[\"lon\"]],\n",
    "                [orig_loc[\"lat\"], repl_loc[\"lat\"]],\n",
    "                color='purple', linestyle='--', linewidth=2.2, alpha=0.9,\n",
    "                transform=ccrs.Geodetic())\n",
    "\n",
    "        # Distance label at midpoint\n",
    "        distance = geodesic(\n",
    "            (orig_loc[\"lat\"], orig_loc[\"lon\"]),\n",
    "            (repl_loc[\"lat\"], repl_loc[\"lon\"])\n",
    "        ).km\n",
    "        mid_lon = (orig_loc[\"lon\"] + repl_loc[\"lon\"]) / 2\n",
    "        mid_lat = (orig_loc[\"lat\"] + repl_loc[\"lat\"]) / 2\n",
    "\n",
    "        ax.text(mid_lon, mid_lat, f\"Distance: {distance:.1f} km\",\n",
    "                verticalalignment='center',\n",
    "                horizontalalignment='center',\n",
    "                transform=ccrs.Geodetic(),\n",
    "                bbox=dict(facecolor='white', alpha=0.85, boxstyle='round'),\n",
    "                fontsize=12, weight='bold')\n",
    "\n",
    "        # DMS coordinate info box\n",
    "        coord_info = (\n",
    "            f\"Original Location:\\n\"\n",
    "            f\"{decimal_to_dms(orig_loc['lat'], True)}\\n\"\n",
    "            f\"{decimal_to_dms(orig_loc['lon'], False)}\\n\\n\"\n",
    "            f\"Ocean Data Point:\\n\"\n",
    "            f\"{decimal_to_dms(repl_loc['lat'], True)}\\n\"\n",
    "            f\"{decimal_to_dms(repl_loc['lon'], False)}\"\n",
    "        )\n",
    "\n",
    "        ax.text(extent[1] - 0.1, extent[3] - 0.1, coord_info,\n",
    "                verticalalignment='top',\n",
    "                horizontalalignment='right',\n",
    "                transform=ccrs.Geodetic(),\n",
    "                bbox=dict(facecolor='white', alpha=0.85, boxstyle='round'),\n",
    "                fontsize=10, family='monospace')\n",
    "\n",
    "        # Legend\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], marker='o', color='w', markerfacecolor='red',\n",
    "                   markersize=10, markeredgecolor='black',\n",
    "                   label='Original Glacier Location'),\n",
    "            Line2D([0], [0], marker='X', color='w', markerfacecolor='blue',\n",
    "                   markersize=10, markeredgecolor='black',\n",
    "                   label='Ocean Data Point (300m depth)')\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, loc='lower left', fontsize=10)\n",
    "\n",
    "        plt.title(f\"{glacier}: Glacier Location vs Ocean Data Point\",\n",
    "                  fontsize=16, pad=15, weight='bold')\n",
    "\n",
    "        save_path = os.path.join(\n",
    "            output_folder,\n",
    "            f\"{glacier.replace(' ', '_')}_Comparison.png\"\n",
    "        )\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        saved_paths.append(save_path)\n",
    "        plt.close()\n",
    "\n",
    "    return saved_paths\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"GEOSPATIAL VISUALISATION PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"\\nCreating Greenland Overview Map...\")\n",
    "    overview_path = create_greenland_map()\n",
    "    print(f\"  Greenland overview saved: {overview_path}\")\n",
    "\n",
    "    print(\"\\nCreating Individual Glacier Detail Maps...\")\n",
    "    detail_paths = create_glacier_detail_maps()\n",
    "    for path in detail_paths:\n",
    "        print(f\"  Detail map saved: {path}\")\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"All maps generated successfully.\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198c047-0480-4969-b1b4-118ca85b764d",
   "metadata": {},
   "source": [
    "## Section 3: Comparative Analysis of Greenland Glacier Summer (JJA) Dynamics: Ice Discharge, Runoff, and Submarine Melt Rate Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12afc8-a40e-4618-a603-3c1df532a91e",
   "metadata": {},
   "source": [
    "This visualization system employs a multi-variable approach using glacier runoff and ice discharge data from Karlsson et al. (2023), with all hydrological variables converted from native units (m³/month) to m³/s for physical interpretability and consistency with the submarine melt rate parameterization. (Section 5) Individual glacier trajectories are represented as semi-transparent lines with region-coded coloring, using dark red at 40% opacity (alpha=0.4) for northeast (NE) glaciers and dark blue at 40% opacity for southeast (SE) glaciers. Regional aggregates are displayed as bold 3-point-width solid lines to enable clear sector-wide comparisons. The system implements intelligent annotations through auto-positioned labels featuring a coordinate-space buffer system for collision avoidance, with white-bordered text connected by directional arrows rendered at 50% opacity (alpha=0.5) using a '->' arrowstyle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e375300d-b250-4c98-ad5c-59e8f62aaabd",
   "metadata": {},
   "source": [
    "Technical implementation features include publication-grade 300DPI JPEG outputs with standardized filename conventions (regional_[Runoff|IceDischarge|SubmarineMeltRate]_comparison.png), powered by a dynamic layout engine. This engine provides configurable legend positioning (upper-left for runoff plots with adjustments for ice discharge displays), optimized reference grids using dotted lines at 30% opacity (alpha=0.3), and responsive title formatting with 14-point bold font and 15-padding. Robust data integrity safeguards are implemented through type validation during CSV ingestion, NaN-aware statistical aggregation, and precise region-specific data partitioning along the 69°N boundary separating NE and SE sectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454bd07f-74d8-4b6f-8afb-8782feb8aedf",
   "metadata": {},
   "source": [
    "The system generates dual visualizations for runoff and ice discharge through a shared rendering pipeline that maintains strict visual consistency. This is achieved via unified color schemes (NE=#8B0000 [darkred], SE=#00008B [darkblue]), synchronized temporal axes spanning 2010-2020 with integer-year ticks, and identical annotation styling using 10-point bold font within 0.3-padded rounded borders. The integrated analytical approach enables simultaneous macro/micro-scale examination through three innovative techniques: visual layering combining base individual glacier plots with regional mean overlays; contextual labeling with terminal-point annotations implementing value-space collision avoidance; and dynamic scaling with auto-adjusted y-axes in m³/s for each hydrological variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb2260-c1c3-436f-8cdc-282bccca5919",
   "metadata": {},
   "source": [
    "A third time-series visualization presents estimated submarine melt rates (m/day) computed using the Slater & Straneo (2022) buoyant plume parameterization (ṁ = 0.142 × Q⁰·³¹ × TF¹·¹⁹), where subglacial discharge Q (m³/s) is derived from Karlsson et al. (2023) runoff data and thermal forcing TF (°C) from ORAS5 300m-depth potential temperatures (Section 1). This figure follows the same dual-layer visualization approach—individual glacier trajectories with regional mean overlays—enabling direct visual comparison with ice discharge patterns. The conversion from m³/month to m³/s uses a standard month of 30.44 days (30.44 × 86,400 = 2,630,016 seconds/month)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d1ebe39-e34d-4b76-b779-ac913596b5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GLACIER DYNAMICS TIME SERIES PIPELINE\n",
      "============================================================\n",
      "\n",
      "Loading Karlsson et al. (2023) glacier data...\n",
      "  Processing Helheim Gletsjer...\n",
      "  Processing Storebjoern...\n",
      "  Processing Daugaard-Jensen Gletsjer...\n",
      "  Processing Waltershausen Gletsjer...\n",
      "\n",
      "Generating line plots...\n",
      "  Saved: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/regional_Runoff_comparison.png\n",
      "  Saved: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/regional_IceDischarge_comparison.png\n",
      "\n",
      "Generating Submarine Melt Rate plot...\n",
      "  Saved: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/regional_SubmarineMeltRate_comparison.png\n",
      "\n",
      "  Submarine Melt Rate Statistics:\n",
      "    SE Regional Mean: 7.19 m/day\n",
      "    NE Regional Mean: 1.73 m/day\n",
      "    Difference: 5.46 m/day (~4.2x)\n",
      "\n",
      "============================================================\n",
      "All time-series plots generated successfully.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 3: Glacier Dynamics — Summer (JJA) Time Series Visualisation\n",
    "# =============================================================================\n",
    "# This script produces three time-series line plots comparing NE and SE\n",
    "# Greenland glacier dynamics over 2010–2020 (summer JJA averages):\n",
    "#\n",
    "#   (1) Runoff (m³/s) — individual glaciers + regional horizontal means\n",
    "#   (2) Ice Discharge (m³/s) — individual glaciers + regional means,\n",
    "#       with a double-headed arrow annotating the inter-regional difference\n",
    "#   (3) Submarine Melt Rate (m/day) — individual glaciers + regional means,\n",
    "#       from Slater & Straneo (2022) parameterisation applied in Section 5\n",
    "#\n",
    "# Runoff and Ice Discharge source data are in m³/month (Karlsson et al., 2023).\n",
    "# Conversion to m³/s: divide by (30.44 × 86400) = 2,630,016 seconds/month.\n",
    "# Submarine Melt Rate is pre-computed in m/day by Section 5 Code 1.\n",
    "#\n",
    "# Dependencies:\n",
    "#   - Karlsson et al. (2023) individual glacier CSVs (Runoff, Ice Discharge)\n",
    "#   - individual_glaciers_summer.csv from Section 5 (Submarine Melt Rate)\n",
    "#     → Section 5 must be executed first to generate this file\n",
    "#\n",
    "# Output: Three PNG figures saved to the plots/ directory\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# =====================================================================\n",
    "# Configuration\n",
    "# =====================================================================\n",
    "\n",
    "# Karlsson et al. (2023) individual glacier data files\n",
    "data_paths = {\n",
    "    \"Helheim Gletsjer\": \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/HelheimGletsjer_SE_D231.csv\",\n",
    "    \"Storebjoern\": \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/Storebjoern_SE_D299.csv\",\n",
    "    \"Daugaard-Jensen Gletsjer\": \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/Daugaard-JensenGletsjer_CE_D140.csv\",\n",
    "    \"Waltershausen Gletsjer\": \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/WaltershausenGletsjer_NE_D114.csv\"\n",
    "}\n",
    "\n",
    "# Regional classification (divided at 69°N; Seale et al., 2011)\n",
    "region_tags = {\n",
    "    \"Helheim Gletsjer\": \"SE\",\n",
    "    \"Storebjoern\": \"SE\",\n",
    "    \"Daugaard-Jensen Gletsjer\": \"NE\",\n",
    "    \"Waltershausen Gletsjer\": \"NE\"\n",
    "}\n",
    "\n",
    "output_folder = \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Unit conversion constant: m³/month → m³/s\n",
    "# Average month = 30.44 days; 30.44 × 86400 = 2,630,016 seconds\n",
    "SECONDS_PER_MONTH = 30.44 * 86400\n",
    "\n",
    "# Visual settings\n",
    "REGION_COLORS = {'NE': 'darkred', 'SE': 'darkblue'}\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Data Loading and Preprocessing\n",
    "# =====================================================================\n",
    "\n",
    "def load_and_preprocess(path):\n",
    "    \"\"\"\n",
    "    Load and clean a Karlsson et al. (2023) glacier CSV file.\n",
    "\n",
    "    The raw CSVs have two header rows; this function extracts the\n",
    "    correct column names, parses dates, and converts Runoff and\n",
    "    IceDischarge columns to numeric types.\n",
    "\n",
    "    Args:\n",
    "        path (str): File path to the glacier CSV.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned dataframe with Date, Year, Month,\n",
    "                      Runoff (m³/month), and IceDischarge (m³/month).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df_clean = df[2:].copy()\n",
    "    df_clean.columns = df.iloc[1]\n",
    "    df_clean.rename(columns={\"Date_YYYY-MM\": \"Date\"}, inplace=True)\n",
    "    df_clean[\"Date\"] = pd.to_datetime(df_clean[\"Date\"])\n",
    "    df_clean[\"Year\"] = df_clean[\"Date\"].dt.year\n",
    "    df_clean[\"Month\"] = df_clean[\"Date\"].dt.month\n",
    "    df_clean[\"Runoff\"] = pd.to_numeric(df_clean[\"Runoff\"], errors='coerce')\n",
    "    df_clean[\"IceDischarge\"] = pd.to_numeric(df_clean[\"IceDischarge\"], errors='coerce')\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def get_summer_averages(df):\n",
    "    \"\"\"\n",
    "    Compute summer (JJA) annual averages for Runoff and Ice Discharge.\n",
    "\n",
    "    Filters for June, July, and August, then groups by year to\n",
    "    calculate the mean of each variable in the original m³/month units.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Preprocessed glacier dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Yearly JJA averages with columns Year, Runoff,\n",
    "                      IceDischarge (all in m³/month).\n",
    "    \"\"\"\n",
    "    summer_df = df[df[\"Month\"].isin([6, 7, 8])]\n",
    "    return summer_df.groupby(\"Year\").agg({\n",
    "        \"Runoff\": \"mean\",\n",
    "        \"IceDischarge\": \"mean\"\n",
    "    }).reset_index()\n",
    "\n",
    "\n",
    "def get_regional_data(all_data):\n",
    "    \"\"\"\n",
    "    Aggregate individual glacier data into NE and SE regional groups.\n",
    "\n",
    "    For each region, combines all glacier time series and computes\n",
    "    the inter-glacier mean per year. Used for plotting individual\n",
    "    traces and regional mean horizontal lines.\n",
    "\n",
    "    Args:\n",
    "        all_data (dict): {glacier_name: summer_avg_dataframe}.\n",
    "\n",
    "    Returns:\n",
    "        dict: {region: {'individual': combined_df, 'mean': regional_mean_df}}.\n",
    "    \"\"\"\n",
    "    regional_data = {}\n",
    "    for region in ['NE', 'SE']:\n",
    "        region_dfs = []\n",
    "        for glacier, data in all_data.items():\n",
    "            if region_tags[glacier] == region:\n",
    "                df = data.copy()\n",
    "                df['Glacier'] = glacier\n",
    "                region_dfs.append(df)\n",
    "        combined = pd.concat(region_dfs)\n",
    "        regional_mean = combined.groupby('Year').mean(numeric_only=True).reset_index()\n",
    "        regional_data[region] = {\n",
    "            'individual': combined,\n",
    "            'mean': regional_mean\n",
    "        }\n",
    "    return regional_data\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Figure 1 & 2: Runoff and Ice Discharge Line Plots\n",
    "# =====================================================================\n",
    "\n",
    "def create_combined_line_plot(all_data, regional_data, variable):\n",
    "    \"\"\"\n",
    "    Create a time-series line plot for Runoff or Ice Discharge (m³/s).\n",
    "\n",
    "    Plots individual glacier traces (thin, semi-transparent) and\n",
    "    regional mean horizontal lines (thick, solid) for NE and SE.\n",
    "    For Ice Discharge, a double-headed arrow annotates the\n",
    "    inter-regional magnitude difference.\n",
    "\n",
    "    Args:\n",
    "        all_data (dict): Individual glacier summer average data.\n",
    "        regional_data (dict): Regional aggregation from get_regional_data().\n",
    "        variable (str): 'Runoff' or 'IceDischarge'.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Format variable name for axis labels and title\n",
    "    display_var = \"Ice Discharge\" if variable == \"IceDischarge\" else variable\n",
    "\n",
    "    legend_elements = []\n",
    "\n",
    "    # --- Individual glacier traces ---\n",
    "    label_positions = {}\n",
    "    for region in ['NE', 'SE']:\n",
    "        color = REGION_COLORS[region]\n",
    "        region_df = regional_data[region]['individual']\n",
    "\n",
    "        for glacier in region_df['Glacier'].unique():\n",
    "            glacier_data = region_df[region_df['Glacier'] == glacier]\n",
    "            # Convert from m³/month to m³/s at plot time\n",
    "            scaled_data = glacier_data[variable] / SECONDS_PER_MONTH\n",
    "            plt.plot(glacier_data['Year'], scaled_data,\n",
    "                     color=color, alpha=0.4, linewidth=1.5)\n",
    "\n",
    "            # Annotated glacier name labels at end of each trace\n",
    "            last_year = glacier_data['Year'].iloc[-1]\n",
    "            last_value = scaled_data.iloc[-1]\n",
    "            key = (last_year, round(last_value, 1))\n",
    "\n",
    "            if key not in label_positions:\n",
    "                y_offset = 0\n",
    "                for existing_key in label_positions.keys():\n",
    "                    if abs(existing_key[0] - last_year) < 1:\n",
    "                        y_offset += 0.8\n",
    "\n",
    "                plt.annotate(\n",
    "                    glacier,\n",
    "                    xy=(last_year, last_value),\n",
    "                    xytext=(last_year + 0.5, last_value + y_offset),\n",
    "                    color=color, fontsize=10, weight='bold',\n",
    "                    arrowprops=dict(arrowstyle='->', color=color, alpha=0.5),\n",
    "                    bbox=dict(boxstyle='round,pad=0.3',\n",
    "                              facecolor='white', alpha=0.8, edgecolor=color)\n",
    "                )\n",
    "                label_positions[key] = True\n",
    "\n",
    "        legend_elements.append(\n",
    "            Line2D([0], [0], color=color, alpha=0.4, lw=1.5,\n",
    "                   label=f'{region} Individual Glaciers'))\n",
    "\n",
    "    # --- Regional mean horizontal lines ---\n",
    "    regional_mean_values = {}\n",
    "    for region in ['NE', 'SE']:\n",
    "        color = REGION_COLORS[region]\n",
    "        mean_data = regional_data[region]['mean']\n",
    "\n",
    "        # Overall period mean, converted to m³/s\n",
    "        regional_mean_value = mean_data[variable].mean() / SECONDS_PER_MONTH\n",
    "        regional_mean_values[region] = regional_mean_value\n",
    "\n",
    "        plt.axhline(y=regional_mean_value, color=color,\n",
    "                     linewidth=3, linestyle='-', alpha=0.8)\n",
    "\n",
    "        legend_elements.append(\n",
    "            Line2D([0], [0], color=color, lw=3, linestyle='-',\n",
    "                   label=f'{region} Regional Mean ({regional_mean_value:.2f} m\\u00b3/s)'))\n",
    "\n",
    "    # --- Difference annotation (Ice Discharge only) ---\n",
    "    if variable == \"IceDischarge\":\n",
    "        se_mean = regional_mean_values['SE']\n",
    "        ne_mean = regional_mean_values['NE']\n",
    "        difference = se_mean - ne_mean\n",
    "        ratio = se_mean / ne_mean\n",
    "\n",
    "        mid_year = 2015\n",
    "        mid_value = (se_mean + ne_mean) / 2\n",
    "\n",
    "        plt.annotate('',\n",
    "                     xy=(mid_year, se_mean),\n",
    "                     xytext=(mid_year, ne_mean),\n",
    "                     arrowprops=dict(arrowstyle='<->',\n",
    "                                     lw=2.5, color='black',\n",
    "                                     shrinkA=0, shrinkB=0))\n",
    "\n",
    "        plt.text(mid_year + 0.3, mid_value,\n",
    "                 f'~{ratio:.1f}\\u00d7 difference\\n({difference:.1f} m\\u00b3/s)',\n",
    "                 fontsize=12, fontweight='bold', va='center',\n",
    "                 bbox=dict(boxstyle='round,pad=0.5',\n",
    "                           facecolor='yellow', alpha=0.7,\n",
    "                           edgecolor='black', linewidth=2))\n",
    "\n",
    "    # --- Styling ---\n",
    "    plt.title(f\"Regional Mean Summer (JJA) {display_var} Comparison (2010\\u20132020)\",\n",
    "              fontsize=14, pad=15, weight='bold')\n",
    "    plt.xlabel(\"Year\", fontsize=12)\n",
    "    plt.ylabel(f\"{display_var} (m\\u00b3/s)\", fontsize=12)\n",
    "    plt.xticks(range(2010, 2021))\n",
    "    plt.grid(True, linestyle=':', alpha=0.3)\n",
    "\n",
    "    legend_bbox = (1, 0.85) if variable == \"IceDischarge\" else (1, 1)\n",
    "    plt.legend(handles=legend_elements, loc='upper left',\n",
    "               bbox_to_anchor=legend_bbox, framealpha=1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    save_path = os.path.join(output_folder, f\"regional_{variable}_comparison.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  Saved: {save_path}\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Figure 3: Submarine Melt Rate Line Plot\n",
    "# =====================================================================\n",
    "\n",
    "def create_submarine_melt_plot():\n",
    "    \"\"\"\n",
    "    Create a time-series line plot for Submarine Melt Rate (m/day).\n",
    "\n",
    "    Reads pre-computed SubmarineDischarge values from the Section 5\n",
    "    output CSV (individual_glaciers_summer.csv). Values are already\n",
    "    in m/day, calculated using Slater & Straneo (2022):\n",
    "        m_dot = 0.142 * Q^0.31 * TF^1.19\n",
    "    where Q is subglacial discharge in m³/s.\n",
    "\n",
    "    Visual style matches the Runoff and Ice Discharge line plots.\n",
    "    Requires Section 5 Code 1 to have been executed first.\n",
    "    \"\"\"\n",
    "    csv_path = '/Users/kyle/Documents/dissertation/Karlsson et al., 2023/tables/individual_glaciers_summer.csv'\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"  CSV not found: {csv_path}\")\n",
    "        print(\"  Run Section 5 (data integration) first to generate this file.\")\n",
    "        return\n",
    "\n",
    "    combined_df = pd.read_csv(csv_path)\n",
    "\n",
    "    if 'SubmarineDischarge' not in combined_df.columns:\n",
    "        print(\"  'SubmarineDischarge' column not found in CSV.\")\n",
    "        print(\"  Ensure Section 5 code includes submarine melt rate calculation.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    legend_elements = []\n",
    "    label_positions = {}\n",
    "\n",
    "    # Prepare regional data structures\n",
    "    regional_data = {}\n",
    "    for region in ['NE', 'SE']:\n",
    "        region_df = combined_df[combined_df['Region'] == region].copy()\n",
    "        regional_mean = region_df.groupby('Year')['SubmarineDischarge'].mean().reset_index()\n",
    "        regional_data[region] = {\n",
    "            'individual': region_df,\n",
    "            'mean': regional_mean\n",
    "        }\n",
    "\n",
    "    # --- Individual glacier traces ---\n",
    "    for region in ['NE', 'SE']:\n",
    "        color = REGION_COLORS[region]\n",
    "        region_df = regional_data[region]['individual']\n",
    "\n",
    "        for glacier in region_df['Glacier'].unique():\n",
    "            glacier_data = region_df[region_df['Glacier'] == glacier]\n",
    "            plt.plot(glacier_data['Year'], glacier_data['SubmarineDischarge'],\n",
    "                     color=color, alpha=0.4, linewidth=1.5)\n",
    "\n",
    "            # Annotated glacier name labels\n",
    "            last_year = glacier_data['Year'].iloc[-1]\n",
    "            last_value = glacier_data['SubmarineDischarge'].iloc[-1]\n",
    "            key = (last_year, round(last_value, 1))\n",
    "\n",
    "            if key not in label_positions:\n",
    "                y_offset = 0\n",
    "                for existing_key in label_positions.keys():\n",
    "                    if abs(existing_key[0] - last_year) < 1:\n",
    "                        y_offset += 0.8\n",
    "\n",
    "                plt.annotate(\n",
    "                    glacier,\n",
    "                    xy=(last_year, last_value),\n",
    "                    xytext=(last_year + 0.5, last_value + y_offset),\n",
    "                    color=color, fontsize=10, weight='bold',\n",
    "                    arrowprops=dict(arrowstyle='->', color=color, alpha=0.5),\n",
    "                    bbox=dict(boxstyle='round,pad=0.3',\n",
    "                              facecolor='white', alpha=0.8, edgecolor=color)\n",
    "                )\n",
    "                label_positions[key] = True\n",
    "\n",
    "        legend_elements.append(\n",
    "            Line2D([0], [0], color=color, alpha=0.4, lw=1.5,\n",
    "                   label=f'{region} Individual Glaciers'))\n",
    "\n",
    "    # --- Regional mean horizontal lines ---\n",
    "    regional_mean_values = {}\n",
    "    for region in ['NE', 'SE']:\n",
    "        color = REGION_COLORS[region]\n",
    "        mean_val = regional_data[region]['mean']['SubmarineDischarge'].mean()\n",
    "        regional_mean_values[region] = mean_val\n",
    "\n",
    "        plt.axhline(y=mean_val, color=color,\n",
    "                     linewidth=3, linestyle='-', alpha=0.8)\n",
    "        legend_elements.append(\n",
    "            Line2D([0], [0], color=color, lw=3, linestyle='-',\n",
    "                   label=f'{region} Regional Mean ({mean_val:.2f} m/day)'))\n",
    "\n",
    "    # --- Difference annotation ---\n",
    "    se_mean = regional_mean_values['SE']\n",
    "    ne_mean = regional_mean_values['NE']\n",
    "    difference = se_mean - ne_mean\n",
    "    ratio = se_mean / ne_mean if ne_mean > 0 else float('inf')\n",
    "\n",
    "    mid_year = 2015\n",
    "    mid_value = (se_mean + ne_mean) / 2\n",
    "\n",
    "    plt.annotate('',\n",
    "                 xy=(mid_year, se_mean),\n",
    "                 xytext=(mid_year, ne_mean),\n",
    "                 arrowprops=dict(arrowstyle='<->',\n",
    "                                 lw=2.5, color='black',\n",
    "                                 shrinkA=0, shrinkB=0))\n",
    "\n",
    "    plt.text(mid_year + 0.3, mid_value,\n",
    "             f'~{ratio:.1f}\\u00d7 difference\\n({difference:.2f} m/day)',\n",
    "             fontsize=12, fontweight='bold', va='center',\n",
    "             bbox=dict(boxstyle='round,pad=0.5',\n",
    "                       facecolor='yellow', alpha=0.7,\n",
    "                       edgecolor='black', linewidth=2))\n",
    "\n",
    "    # --- Styling ---\n",
    "    plt.title(\"Regional Mean Summer (JJA) Submarine Melt Rate Comparison (2010\\u20132020)\",\n",
    "              fontsize=14, pad=15, weight='bold')\n",
    "    plt.xlabel(\"Year\", fontsize=12)\n",
    "    plt.ylabel(\"Submarine Melt Rate (m/day)\", fontsize=12)\n",
    "    plt.xticks(range(2010, 2021))\n",
    "    plt.grid(True, linestyle=':', alpha=0.3)\n",
    "\n",
    "    plt.legend(handles=legend_elements, loc='upper left',\n",
    "               bbox_to_anchor=(1, 1), framealpha=1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    save_path = os.path.join(output_folder, \"regional_SubmarineMeltRate_comparison.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  Saved: {save_path}\")\n",
    "    print(f\"\\n  Submarine Melt Rate Statistics:\")\n",
    "    print(f\"    SE Regional Mean: {se_mean:.2f} m/day\")\n",
    "    print(f\"    NE Regional Mean: {ne_mean:.2f} m/day\")\n",
    "    print(f\"    Difference: {difference:.2f} m/day (~{ratio:.1f}x)\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"GLACIER DYNAMICS TIME SERIES PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Step 1: Load and preprocess individual glacier data\n",
    "    print(\"\\nLoading Karlsson et al. (2023) glacier data...\")\n",
    "    all_glacier_data = {}\n",
    "    for glacier, path in data_paths.items():\n",
    "        print(f\"  Processing {glacier}...\")\n",
    "        df = load_and_preprocess(path)\n",
    "        summer_avg = get_summer_averages(df)\n",
    "        all_glacier_data[glacier] = summer_avg\n",
    "\n",
    "    # Step 2: Aggregate into regional groups\n",
    "    regional_data = get_regional_data(all_glacier_data)\n",
    "\n",
    "    # Step 3: Generate Runoff and Ice Discharge line plots (m³/s)\n",
    "    print(\"\\nGenerating line plots...\")\n",
    "    create_combined_line_plot(all_glacier_data, regional_data, \"Runoff\")\n",
    "    create_combined_line_plot(all_glacier_data, regional_data, \"IceDischarge\")\n",
    "\n",
    "    # Step 4: Generate Submarine Melt Rate line plot (m/day)\n",
    "    # Requires individual_glaciers_summer.csv from Section 5\n",
    "    print(\"\\nGenerating Submarine Melt Rate plot...\")\n",
    "    create_submarine_melt_plot()\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"All time-series plots generated successfully.\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e449f1c4-9d2a-4483-b88e-141ed10d349a",
   "metadata": {},
   "source": [
    "## Section 4: Ocean Potential Temperature Analysis at Greenland Glacier Margins (2010-2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec252b79-36b5-4cc3-9718-9bba2aadf6b2",
   "metadata": {},
   "source": [
    "This study implements a comprehensive analytical workflow to examine summer (JJA) potential temperature patterns near four major Greenland glaciers using ORAS5 reanalysis data (CDS, 2021). The methodology begins with systematic data acquisition, loading monthly 3D temperature fields from NetCDF files while incorporating manually validated data points for July 2015 derived from the nearest available grid cells in the original ORAS5 file (votemper_control_monthly_highres_3D_201507_OPER_v0.1.nc), as identified through the spatial search algorithm detailed in Section 1. Each processing step includes rigorous coordinate system validation, verifying that data falls within expected Greenlandic boundaries (50-85°N, -75--10°E) and automatically correcting for latitude axis orientation when necessary. This visualization presents the 300m-depth potential temperature data extracted in Section 1 as regional time series, enabling visual assessment of interannual variability and NE/SE thermal contrasts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a98a0c-6c61-4e23-bc87-c4f2d3bfc1a3",
   "metadata": {},
   "source": [
    "The core analysis extracts potential temperatures at glacier-adjacent ocean grid points through an optimized grid-point selection algorithm that minimizes Euclidean distance between dataset coordinates and predefined glacier termini positions, building directly on the methodology established in Section 1. Spatial validation metrics are computed with geodesic distance calculations (reported to 2 decimal places in kilometers) from target locations for each data point. Summer (JJA) means are calculated by averaging June-August temperatures, with the resulting time series undergoing quality checks for completeness and physical plausibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ffff75-9de1-4430-92b8-02eee8f5253a",
   "metadata": {},
   "source": [
    "Visualization employs a dual-layer approach combining individual glacier trends with regional aggregates. Semi-transparent lines (α=0.4) in region-specific colors (NE=#8B0000 [darkred], SE=#00008B [darkblue]) represent single-glacier observations, while bold solid lines show sector-wide averages. An intelligent labeling system positions glacier identifiers at line endpoints with automatic collision avoidance, using white-background annotations connected by directional arrows. The plotting framework includes zero-reference lines, decade-year ticks, and dynamic legend placement optimized for readability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d571b5-b211-4131-984b-7bf7338c733f",
   "metadata": {},
   "source": [
    "Technical implementation features robust error handling with formatted runtime messages (including filename/year tags for processing alerts), validation warnings, and configurable output settings. High-resolution (300 DPI) PNG visualizations are systematically saved with standardized nomenclature (\"regional_temperature_comparison.png\"), maintaining consistency with other sections' output formats. This integrated approach enables simultaneous examination of local thermal anomalies and regional climate patterns, with Section 1's extraction methodology and the current time-series visualization together providing insights into interannual variability of subsurface oceanographic conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c6b0806-bb45-42a8-b44e-b826a7453c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OCEAN TEMPERATURE TIME SERIES PIPELINE\n",
      "============================================================\n",
      "\n",
      "Processing Helheim Gletsjer (65.2358°N, -37.9326°E)...\n",
      "  11 years extracted (mean: 4.66°C)\n",
      "\n",
      "Processing Storebjoern (62.9264°N, -40.8969°E)...\n",
      "  11 years extracted (mean: 4.85°C)\n",
      "\n",
      "Processing Daugaard-Jensen Gletsjer (71.1908°N, -25.1324°E)...\n",
      "  11 years extracted (mean: -0.01°C)\n",
      "\n",
      "Processing Waltershausen Gletsjer (72.0131°N, -22.0269°E)...\n",
      "  11 years extracted (mean: 0.12°C)\n",
      "\n",
      "  Saved: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/regional_temperature_comparison.png\n",
      "\n",
      "  Temperature Statistics:\n",
      "    SE Regional Mean: 4.75°C\n",
      "    NE Regional Mean: 0.06°C\n",
      "    Difference: 4.70°C\n",
      "\n",
      "============================================================\n",
      "Temperature analysis completed.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 4: Ocean Temperature — Summer (JJA) Time Series Visualisation\n",
    "# =============================================================================\n",
    "# This script extracts 300m-depth ocean potential temperature from ORAS5\n",
    "# reanalysis (CDS, 2021) and produces a regional comparison line plot\n",
    "# for NE and SE Greenland glaciers over 2010–2020.\n",
    "#\n",
    "# Unlike Section 1 Code 2 (which outputs a CSV), this script combines\n",
    "# data extraction and visualisation in a single pipeline. It reads\n",
    "# individual ORAS5 NetCDF files for each JJA month, extracts temperature\n",
    "# at the replacement ocean grid point for each glacier, and plots:\n",
    "#   - Individual glacier traces (thin, semi-transparent)\n",
    "#   - Regional mean horizontal lines (thick, solid)\n",
    "#   - Inter-regional temperature difference annotation\n",
    "#\n",
    "# Grid point matching uses Euclidean distance minimisation on the ORAS5\n",
    "# curvilinear grid (nav_lat, nav_lon), consistent with Section 1 Code 2.\n",
    "#\n",
    "# Note: July 2015 uses manually verified values from Section 1 extraction\n",
    "# due to a file-format inconsistency in the OPER/CONS transition period.\n",
    "#\n",
    "# Data source: ORAS5 ocean reanalysis (CDS, 2021)\n",
    "# Target depth: 300m (dynamically resolved via depth index search)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# =====================================================================\n",
    "# Configuration\n",
    "# =====================================================================\n",
    "\n",
    "base_dir = \"/Users/kyle/Documents/dissertation/ORAS5/votemper\"\n",
    "output_folder = \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Replacement coordinates: nearest valid ORAS5 ocean grid points at 300m\n",
    "# depth, identified by Section 1 Code 1\n",
    "replacement_locations = {\n",
    "    \"Helheim Gletsjer\":         {\"lat\": 65.2358, \"lon\": -37.9326},   \n",
    "    \"Storebjoern\":              {\"lat\": 62.9264, \"lon\": -40.8969},   \n",
    "    \"Daugaard-Jensen Gletsjer\": {\"lat\": 71.1908, \"lon\": -25.1324},   \n",
    "    \"Waltershausen Gletsjer\":   {\"lat\": 72.0131, \"lon\": -22.0269}    \n",
    "}\n",
    "\n",
    "# Regional classification (divided at 69°N; Seale et al., 2011)\n",
    "region_tags = {\n",
    "    \"Helheim Gletsjer\": \"SE\",\n",
    "    \"Storebjoern\": \"SE\",\n",
    "    \"Daugaard-Jensen Gletsjer\": \"NE\",\n",
    "    \"Waltershausen Gletsjer\": \"NE\"\n",
    "}\n",
    "\n",
    "# Visual settings\n",
    "REGION_COLORS = {'NE': 'darkred', 'SE': 'darkblue'}\n",
    "\n",
    "# Manually verified July 2015 temperatures from Section 1 extraction.\n",
    "# Used as fallback for the OPER/CONS file-format transition period.\n",
    "MANUAL_DATA_JULY_2015 = {\n",
    "    \"Helheim Gletsjer\": 4.33,\n",
    "    \"Storebjoern\": 4.66,\n",
    "    \"Daugaard-Jensen Gletsjer\": 0.01,\n",
    "    \"Waltershausen Gletsjer\": -0.04\n",
    "}\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Main Pipeline: Data Extraction + Visualisation\n",
    "# =====================================================================\n",
    "\n",
    "def create_combined_temperature_plot():\n",
    "    \"\"\"\n",
    "    Extract 300m-depth ORAS5 temperature for each glacier across\n",
    "    2010–2020 JJA months and produce a regional comparison line plot.\n",
    "\n",
    "    Extraction method:\n",
    "        1. For each year and JJA month, open the corresponding NetCDF file.\n",
    "        2. Find the depth index closest to 300m (dynamic search).\n",
    "        3. Locate the nearest grid point to each glacier's replacement\n",
    "           coordinates via Euclidean distance minimisation.\n",
    "        4. Extract the temperature value; skip NaN (land-masked) cells.\n",
    "\n",
    "    The resulting plot shows individual glacier traces and regional\n",
    "    mean horizontal lines with an inter-regional difference annotation.\n",
    "    \"\"\"\n",
    "    # --- Data extraction ---\n",
    "    all_glacier_data = {}\n",
    "\n",
    "    for glacier, loc in replacement_locations.items():\n",
    "        print(f\"\\nProcessing {glacier} ({loc['lat']:.4f}°N, {loc['lon']:.4f}°E)...\")\n",
    "        yearly_data = []\n",
    "\n",
    "        for year in range(2010, 2021):\n",
    "            summer_temps = []\n",
    "\n",
    "            for month in [6, 7, 8]:\n",
    "                # Use manually verified data for July 2015\n",
    "                if year == 2015 and month == 7:\n",
    "                    temp = MANUAL_DATA_JULY_2015.get(glacier, np.nan)\n",
    "                    if not np.isnan(temp):\n",
    "                        summer_temps.append(temp)\n",
    "                    continue\n",
    "\n",
    "                # Determine file prefix (CONS before June 2015, OPER after)\n",
    "                prefix = \"CONS\" if year < 2015 or (year == 2015 and month < 6) else \"OPER\"\n",
    "                file_name = f\"votemper_control_monthly_highres_3D_{year}{month:02d}_{prefix}_v0.1.nc\"\n",
    "                file_path = os.path.join(base_dir, file_name)\n",
    "\n",
    "                if not os.path.exists(file_path):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    with xr.open_dataset(file_path) as ds:\n",
    "                        # Find depth index closest to 300m (dynamic, not hardcoded)\n",
    "                        depth_idx = np.abs(ds.deptht.values - 300).argmin()\n",
    "\n",
    "                        # Find nearest grid point via Euclidean distance\n",
    "                        dist = (ds.nav_lat - loc['lat'])**2 + (ds.nav_lon - loc['lon'])**2\n",
    "                        y_idx, x_idx = np.unravel_index(\n",
    "                            np.argmin(dist.values), dist.shape\n",
    "                        )\n",
    "\n",
    "                        # Extract temperature at 300m depth\n",
    "                        temp = ds.votemper.isel(\n",
    "                            time_counter=0, deptht=depth_idx,\n",
    "                            y=y_idx, x=x_idx\n",
    "                        ).values.item()\n",
    "\n",
    "                        if not np.isnan(temp):\n",
    "                            summer_temps.append(temp)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error ({year}-{month:02d}): {e}\")\n",
    "\n",
    "            if summer_temps:\n",
    "                yearly_data.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Temp_Avg\": np.mean(summer_temps),\n",
    "                    \"Glacier\": glacier,\n",
    "                    \"Region\": region_tags[glacier]\n",
    "                })\n",
    "\n",
    "        if yearly_data:\n",
    "            all_glacier_data[glacier] = pd.DataFrame(yearly_data)\n",
    "            print(f\"  {len(yearly_data)} years extracted \"\n",
    "                  f\"(mean: {np.mean([d['Temp_Avg'] for d in yearly_data]):.2f}°C)\")\n",
    "\n",
    "    # --- Regional aggregation ---\n",
    "    regional_data = {}\n",
    "    for region in ['NE', 'SE']:\n",
    "        region_dfs = []\n",
    "        for glacier, data in all_glacier_data.items():\n",
    "            if region_tags[glacier] == region:\n",
    "                region_dfs.append(data.copy())\n",
    "        combined = pd.concat(region_dfs)\n",
    "        regional_mean = combined.groupby('Year').agg(\n",
    "            {'Temp_Avg': 'mean'}\n",
    "        ).reset_index()\n",
    "        regional_data[region] = {\n",
    "            'individual': combined,\n",
    "            'mean': regional_mean\n",
    "        }\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    legend_elements = []\n",
    "\n",
    "    # Per-glacier label positioning to avoid overlap\n",
    "    label_properties = {\n",
    "        \"Waltershausen Gletsjer\":   {\"offset\": -0.3, \"ha\": \"left\"},\n",
    "        \"Daugaard-Jensen Gletsjer\": {\"offset\":  0.8, \"ha\": \"left\"},\n",
    "        \"Helheim Gletsjer\":         {\"offset\": -0.3, \"ha\": \"left\"},\n",
    "        \"Storebjoern\":              {\"offset\":  0.7, \"ha\": \"left\"},\n",
    "    }\n",
    "\n",
    "    # Individual glacier traces\n",
    "    for region in ['NE', 'SE']:\n",
    "        color = REGION_COLORS[region]\n",
    "        region_df = regional_data[region]['individual']\n",
    "\n",
    "        for glacier in region_df['Glacier'].unique():\n",
    "            glacier_data = region_df[region_df['Glacier'] == glacier]\n",
    "            plt.plot(glacier_data['Year'], glacier_data['Temp_Avg'],\n",
    "                     color=color, alpha=0.4, linewidth=1.5)\n",
    "\n",
    "            # Annotated glacier name labels at end of trace\n",
    "            last_year = glacier_data['Year'].iloc[-1]\n",
    "            last_value = glacier_data['Temp_Avg'].iloc[-1]\n",
    "\n",
    "            props = label_properties.get(glacier, {\"offset\": 0, \"ha\": \"center\"})\n",
    "            y_offset = props[\"offset\"]\n",
    "            ha = props[\"ha\"]\n",
    "\n",
    "            plt.annotate(\n",
    "                glacier,\n",
    "                xy=(last_year, last_value),\n",
    "                xytext=(last_year + (0.3 if ha == \"left\" else -0.3),\n",
    "                        last_value + y_offset),\n",
    "                color=color, fontsize=10, weight='bold',\n",
    "                ha=ha, va='center',\n",
    "                arrowprops=dict(arrowstyle='->', color=color, alpha=0.5,\n",
    "                                relpos=(0.5 if ha == \"center\"\n",
    "                                        else (0.2 if ha == \"left\" else 0.8))),\n",
    "                bbox=dict(boxstyle='round,pad=0.3',\n",
    "                          facecolor='white', alpha=0.8, edgecolor=color)\n",
    "            )\n",
    "\n",
    "        legend_elements.append(\n",
    "            Line2D([0], [0], color=color, alpha=0.4, lw=1.5,\n",
    "                   label=f'{region} Individual Glaciers'))\n",
    "\n",
    "    # Regional mean horizontal lines\n",
    "    regional_mean_values = {}\n",
    "    for region in ['NE', 'SE']:\n",
    "        color = REGION_COLORS[region]\n",
    "        mean_data = regional_data[region]['mean']\n",
    "\n",
    "        regional_mean_value = mean_data['Temp_Avg'].mean()\n",
    "        regional_mean_values[region] = regional_mean_value\n",
    "\n",
    "        plt.axhline(y=regional_mean_value, color=color,\n",
    "                     linewidth=3, linestyle='-', alpha=0.8)\n",
    "\n",
    "        legend_elements.append(\n",
    "            Line2D([0], [0], color=color, lw=3, linestyle='-',\n",
    "                   label=f'{region} Regional Mean ({regional_mean_value:.2f}\\u00b0C)'))\n",
    "\n",
    "    # Inter-regional temperature difference annotation\n",
    "    se_mean = regional_mean_values['SE']\n",
    "    ne_mean = regional_mean_values['NE']\n",
    "    difference = se_mean - ne_mean\n",
    "\n",
    "    mid_year = 2015\n",
    "    mid_value = (se_mean + ne_mean) / 2\n",
    "\n",
    "    plt.annotate('',\n",
    "                 xy=(mid_year, se_mean),\n",
    "                 xytext=(mid_year, ne_mean),\n",
    "                 arrowprops=dict(arrowstyle='<->',\n",
    "                                 lw=2.5, color='black',\n",
    "                                 shrinkA=0, shrinkB=0))\n",
    "\n",
    "    plt.text(mid_year + 0.3, mid_value,\n",
    "             f'{difference:.2f}\\u00b0C difference',\n",
    "             fontsize=12, fontweight='bold', va='center',\n",
    "             bbox=dict(boxstyle='round,pad=0.5',\n",
    "                       facecolor='yellow', alpha=0.7,\n",
    "                       edgecolor='black', linewidth=2))\n",
    "\n",
    "    # Styling\n",
    "    plt.title(\"Regional Mean Summer (JJA) Potential Temperature at 300m Depth (2010\\u20132020)\",\n",
    "              fontsize=14, pad=15, weight='bold')\n",
    "    plt.xlabel(\"Year\", fontsize=12)\n",
    "    plt.ylabel(\"Temperature (\\u00b0C)\", fontsize=12)\n",
    "    plt.xticks(range(2010, 2021))\n",
    "    plt.grid(True, linestyle=':', alpha=0.3)\n",
    "    plt.axhline(0, color='black', linewidth=0.8, zorder=0)\n",
    "\n",
    "    plt.legend(handles=legend_elements, loc='upper left',\n",
    "               bbox_to_anchor=(1, 0.5), framealpha=1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    save_path = os.path.join(output_folder, \"regional_temperature_comparison.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\n  Saved: {save_path}\")\n",
    "    print(f\"\\n  Temperature Statistics:\")\n",
    "    print(f\"    SE Regional Mean: {se_mean:.2f}\\u00b0C\")\n",
    "    print(f\"    NE Regional Mean: {ne_mean:.2f}\\u00b0C\")\n",
    "    print(f\"    Difference: {difference:.2f}\\u00b0C\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"OCEAN TEMPERATURE TIME SERIES PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    create_combined_temperature_plot()\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"Temperature analysis completed.\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f849251-d0d1-4dd0-850b-37bef0d3009a",
   "metadata": {},
   "source": [
    "## Section 5: Integrated Glacier-Ocean Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c69bd12-0acf-4dd2-b01b-2c7dd60ecec1",
   "metadata": {},
   "source": [
    "These scripts combine three key components: glacier discharge processing, ocean temperature analysis, and statistical correlation evaluation. The analysis focuses on four major Greenlandic glaciers (Helheim, Storebjoern, Daugaard-Jensen, and Waltershausen) using glacier runoff and ice discharge from Karlsson et al. (2023) and ORAS5 reanalysis data (CDS, 2021). For discharge measurements, the script processes runoff and ice discharge data by calculating summer (June-August) averages from 2010 to 2020, with careful handling of unit conversions and missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5965a746-b40b-41a0-8bd6-9320a35d5d16",
   "metadata": {},
   "source": [
    "Central to this pipeline is the computation of submarine melt rates using the buoyant plume parameterization from Slater & Straneo (2022): ṁ = 0.142 × Q⁰·³¹ × TF¹·¹⁹, where Q represents subglacial discharge (m³/s) and TF represents thermal forcing (°C), defined as ocean potential temperature minus the pressure-dependent freezing point (−1.9°C at ~300m depth). Critically, the raw runoff data from Karlsson et al. (2023) is provided in m³/month and must be converted to m³/s by dividing by 2,630,016 (= 30.44 days × 86,400 s/day) before application in the parameterization. The resulting melt rate estimates are in m/day, consistent with the parameterization's calibration against LeConte Glacier observations (Jackson et al., 2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afbadd-efa6-4c68-9219-b5f2bc18f678",
   "metadata": {},
   "source": [
    "The temperature analysis utilizes ORAS5 ocean reanalysis data (CDS, 2021), which employs different data production systems across the study period. As specified in the ORAS5 documentation, the dataset transitions from Consolidated (CONS) to Operational (OPER) systems, requiring distinct file naming conventions. The script automatically handles this transition by using CONS prefix files for 2010-2014 and January-May 2015, then switching to OPER prefix for June 2015 onward. Potential temperature values are extracted from the nearest ocean grid points to each glacier's terminus location, with spatial matching through Euclidean distance minimization on the ORAS5 curvilinear grid, consistent with Section 1. The temperature extraction process includes depth-specific selection at 300m and spatial matching through minimum distance calculations between glacier coordinates and model grid points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db5d6b-ef6c-45cd-9ae3-8767dc8edf3f",
   "metadata": {},
   "source": [
    "Statistical analysis examines relationships between estimated submarine melt rates (m/day) and observed ice discharge (m³/s) through Pearson correlation tests at both individual glacier and regional (NE vs SE) scales. Additional correlations between ocean temperature and runoff/ice discharge are computed for completeness. The correlations are evaluated at both individual glacier and regional levels (Northeast vs. Southeast Greenland), with results reported to three decimal places for both coefficients and p-values. Visualization outputs include formatted tables and three separate regression plots: (1) runoff vs. temperature, (2) ice discharge vs. temperature, and (3) submarine melt rate vs. ice discharge—the last being the study's primary analytical figure featuring scatter points with dashed trendlines (NE: #d62728, SE: #1f77b4) against 70% opacity dotted reference grids. The system generates publication-ready 300DPI PNG outputs with standardized dimensions, maintaining methodological transparency through preserved intermediate processing steps and clear connections between raw data sources, analytical methods, and final outputs, while adhering to the project's formatting requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f39d1186-f332-42d4-8e47-4b431a76bd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Discharge Data ===\n",
      "\n",
      "=== Processing Temperature Data ===\n",
      "  Processed Helheim Gletsjer: 11 years of data\n",
      "  Processed Storebjoern: 11 years of data\n",
      "  Processed Daugaard-Jensen Gletsjer: 11 years of data\n",
      "  Processed Waltershausen Gletsjer: 11 years of data\n",
      "\n",
      "  Total data collected: 44 yearly averages\n",
      "\n",
      "=== Calculating Submarine Melt Rates ===\n",
      "\n",
      "=== Submarine Melt Rate Summary (m/day) ===\n",
      "  NE: Mean=1.73, Min=1.28, Max=2.57\n",
      "  SE: Mean=7.19, Min=4.94, Max=10.23\n",
      "\n",
      "  Individual glacier data saved: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/tables/individual_glaciers_summer.csv\n",
      "  Regional means data saved: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/tables/regional_means_summer.csv\n",
      "\n",
      "============================================================\n",
      "DATA SUMMARY\n",
      "============================================================\n",
      "  Total records: 44\n",
      "  Glaciers: 4\n",
      "  Years: 2010-2020\n",
      "  Columns: ['Glacier', 'Region', 'Year', 'Runoff', 'IceDischarge', 'Temp_Avg', 'Temp_Min', 'Temp_Max', 'TF', 'SubmarineDischarge', 'Temp_Data_Points']\n",
      "\n",
      "  Note: Runoff and IceDischarge stored in m³/month (raw).\n",
      "        Convert to m³/s by dividing by 2630016 for plotting/analysis.\n",
      "        SubmarineDischarge is already in m/day (Q converted internally).\n",
      "\n",
      "=== All processing completed ===\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 5, Code 1: Integrated Glacier-Ocean Data Processing Pipeline\n",
    "# =============================================================================\n",
    "# This script combines three key components:\n",
    "# (1) Glacier discharge processing (Runoff & Ice Discharge)\n",
    "# (2) Ocean temperature analysis (ORAS5 300m depth)\n",
    "# (3) Submarine melt rate calculation using Slater & Straneo (2022)\n",
    "#\n",
    "# Parameterization: ṁ = 0.142 × Q^0.31 × TF^1.19\n",
    "#   where Q = subglacial discharge (m³/s), TF = thermal forcing (°C)\n",
    "#   Output: submarine melt rate in m/day\n",
    "#\n",
    "# CRITICAL UNIT CONVERSION:\n",
    "#   Raw Runoff from Karlsson et al. (2023) is in m³/month.\n",
    "#   Must convert to m³/s before applying the parameterization:\n",
    "#   Q (m³/s) = Runoff (m³/month) / (30.44 × 86400)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Configuration\n",
    "output_folder = \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/tables\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 1. Runoff and Ice Discharge data paths (Source: Karlsson et al., 2023)\n",
    "discharge_paths = {\n",
    "    \"Helheim Gletsjer\": \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/HelheimGletsjer_SE_D231.csv\",\n",
    "    \"Storebjoern\": \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/Storebjoern_SE_D299.csv\",\n",
    "    \"Daugaard-Jensen Gletsjer\": \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/Daugaard-JensenGletsjer_CE_D140.csv\",\n",
    "    \"Waltershausen Gletsjer\": \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/WaltershausenGletsjer_NE_D114.csv\"\n",
    "}\n",
    "\n",
    "# 2. Potential Temperature extraction coordinates (Source: CDS, 2021; ORAS5)\n",
    "replacement_locations = {\n",
    "    \"Helheim Gletsjer\":         {\"lat\": 65.2358, \"lon\": -37.9326},   \n",
    "    \"Storebjoern\":              {\"lat\": 62.9264, \"lon\": -40.8969},   \n",
    "    \"Daugaard-Jensen Gletsjer\": {\"lat\": 71.1908, \"lon\": -25.1324},   \n",
    "    \"Waltershausen Gletsjer\":   {\"lat\": 72.0131, \"lon\": -22.0269}    \n",
    "}\n",
    "\n",
    "# Regional classification divided at 69°N (Seale et al., 2011)\n",
    "region_tags = {\n",
    "    \"Helheim Gletsjer\": \"SE\",\n",
    "    \"Storebjoern\": \"SE\",\n",
    "    \"Daugaard-Jensen Gletsjer\": \"NE\",\n",
    "    \"Waltershausen Gletsjer\": \"NE\"\n",
    "}\n",
    "\n",
    "# Unit conversion constant: m³/month → m³/s\n",
    "# Average month = 30.44 days × 86400 seconds/day = 2,630,016 seconds\n",
    "SECONDS_PER_MONTH = 30.44 * 86400\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Runoff / Ice Discharge Processing (Source: Karlsson et al., 2023)\n",
    "# =============================================================================\n",
    "\n",
    "def process_discharge_data():\n",
    "    \"\"\"\n",
    "    Load and process monthly runoff and ice discharge data for four glaciers.\n",
    "\n",
    "    Computes summer (JJA) averages for each year from 2010 to 2020.\n",
    "    Raw values remain in m³/month; unit conversion is applied downstream.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Summer averages with columns Glacier, Region, Year,\n",
    "                      Runoff (m³/month), IceDischarge (m³/month).\n",
    "    \"\"\"\n",
    "    all_discharge_data = []\n",
    "    \n",
    "    for glacier, path in discharge_paths.items():\n",
    "        df = pd.read_csv(path)\n",
    "        df_clean = df[2:].copy()\n",
    "        df_clean.columns = df.iloc[1]\n",
    "        df_clean.rename(columns={\"Date_YYYY-MM\": \"Date\"}, inplace=True)\n",
    "        df_clean[\"Date\"] = pd.to_datetime(df_clean[\"Date\"])\n",
    "        df_clean[\"Year\"] = df_clean[\"Date\"].dt.year\n",
    "        df_clean[\"Month\"] = df_clean[\"Date\"].dt.month\n",
    "        df_clean[\"Runoff\"] = pd.to_numeric(df_clean[\"Runoff\"], errors='coerce')\n",
    "        df_clean[\"IceDischarge\"] = pd.to_numeric(df_clean[\"IceDischarge\"], errors='coerce')\n",
    "        \n",
    "        # Calculate summer (JJA) average\n",
    "        summer_avg = df_clean[df_clean[\"Month\"].isin([6, 7, 8])].groupby(\"Year\").agg({\n",
    "            \"Runoff\": \"mean\",\n",
    "            \"IceDischarge\": \"mean\"\n",
    "        }).reset_index().round(2)\n",
    "        \n",
    "        summer_avg[\"Glacier\"] = glacier\n",
    "        summer_avg[\"Region\"] = region_tags[glacier]\n",
    "        all_discharge_data.append(summer_avg)\n",
    "    \n",
    "    return pd.concat(all_discharge_data)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Potential Temperature Processing (Source: CDS, 2021; ORAS5 at 300m depth)\n",
    "# =============================================================================\n",
    "\n",
    "def process_temperature_data():\n",
    "    \"\"\"\n",
    "    Extract summer (JJA) ocean potential temperature at 300m depth from ORAS5\n",
    "    reanalysis for each glacier's ocean data point (2010–2020).\n",
    "\n",
    "    The ORAS5 dataset transitions from Consolidated (CONS) to Operational (OPER)\n",
    "    production system: CONS for 2010–2014 and Jan–May 2015, OPER from Jun 2015.\n",
    "\n",
    "    July 2015 uses manually validated values derived from the Section 1\n",
    "    spatial search algorithm applied to the original ORAS5 file.\n",
    "\n",
    "    Grid point matching uses Euclidean distance minimisation on the ORAS5\n",
    "    curvilinear grid (nav_lat, nav_lon), consistent with Section 1 Code 2\n",
    "    and Section 4.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Yearly JJA temperature data with columns Glacier,\n",
    "                      Region, Year, Temp_Avg, Temp_Min, Temp_Max,\n",
    "                      Temp_Data_Points.\n",
    "    \"\"\"\n",
    "    base_dir = \"/Users/kyle/Documents/dissertation/ORAS5/votemper\"\n",
    "    \n",
    "    # Manual validation data for July 2015 (Source: Section 1 ORAS5 extraction)\n",
    "    manual_data = {\n",
    "        2015: {\n",
    "            \"Helheim Gletsjer\": 4.33,\n",
    "            \"Storebjoern\": 4.66,\n",
    "            \"Daugaard-Jensen Gletsjer\": 0.01,\n",
    "            \"Waltershausen Gletsjer\": -0.04\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    all_temp_data = []\n",
    "\n",
    "    for glacier, loc in replacement_locations.items():\n",
    "        yearly_data = []\n",
    "        \n",
    "        for year in range(2010, 2021):\n",
    "            summer_temps = []\n",
    "            \n",
    "            for month in [6, 7, 8]:\n",
    "                if year == 2015 and month == 7:\n",
    "                    # Use manually validated value for July 2015\n",
    "                    temp = manual_data[2015].get(glacier, np.nan)\n",
    "                else:\n",
    "                    # Determine file prefix based on ORAS5 production system\n",
    "                    prefix = \"CONS\" if year < 2015 or (year == 2015 and month < 6) else \"OPER\"\n",
    "                    file_name = f\"votemper_control_monthly_highres_3D_{year}{month:02d}_{prefix}_v0.1.nc\"\n",
    "                    file_path = os.path.join(base_dir, file_name)\n",
    "                    \n",
    "                    if os.path.exists(file_path):\n",
    "                        try:\n",
    "                            with xr.open_dataset(file_path) as ds:\n",
    "                                # Find nearest grid point via Euclidean distance\n",
    "                                # (consistent with Section 1 Code 2 and Section 4)\n",
    "                                dist = (ds.nav_lat - loc['lat'])**2 + (ds.nav_lon - loc['lon'])**2\n",
    "                                y_idx, x_idx = np.unravel_index(np.argmin(dist.values), dist.shape)\n",
    "                                \n",
    "                                # Extract temperature at 300m depth (dynamic index)\n",
    "                                depth_idx = np.abs(ds.deptht.values - 300).argmin()\n",
    "                                temp = ds.votemper.isel(\n",
    "                                    time_counter=0, deptht=depth_idx,\n",
    "                                    y=y_idx, x=x_idx\n",
    "                                ).values.item()\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            print(f\"  Error processing {file_name}: {e}\")\n",
    "                            temp = np.nan\n",
    "                    else:\n",
    "                        temp = np.nan\n",
    "                        print(f\"  File not found: {file_name}\")\n",
    "                \n",
    "                if not np.isnan(temp):\n",
    "                    summer_temps.append(temp)\n",
    "            \n",
    "            if summer_temps:\n",
    "                yearly_data.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Temp_Avg\": np.mean(summer_temps).round(3),\n",
    "                    \"Temp_Min\": np.min(summer_temps).round(3),\n",
    "                    \"Temp_Max\": np.max(summer_temps).round(3),\n",
    "                    \"Temp_Data_Points\": len(summer_temps),\n",
    "                })\n",
    "        \n",
    "        if yearly_data:\n",
    "            temp_df = pd.DataFrame(yearly_data)\n",
    "            temp_df[\"Glacier\"] = glacier\n",
    "            temp_df[\"Region\"] = region_tags[glacier]\n",
    "            all_temp_data.append(temp_df)\n",
    "            print(f\"  Processed {glacier}: {len(yearly_data)} years of data\")\n",
    "    \n",
    "    final_df = pd.concat(all_temp_data, ignore_index=True) if all_temp_data else pd.DataFrame()\n",
    "    print(f\"\\n  Total data collected: {len(final_df)} yearly averages\")\n",
    "    return final_df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Submarine Melt Rate Calculation (Slater & Straneo, 2022)\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_submarine_discharge(df):\n",
    "    \"\"\"\n",
    "    Calculate submarine melt rate (m/day) using buoyant plume parameterization:\n",
    "        ṁ = 0.142 × Q^0.31 × TF^1.19\n",
    "\n",
    "    where:\n",
    "        Q  = subglacial discharge in m³/s (converted from m³/month)\n",
    "        TF = thermal forcing in °C (ocean temperature minus freezing point)\n",
    "\n",
    "    The freezing point at ~300m depth is approximately -1.9°C.\n",
    "\n",
    "    Validation reference (Donald Slater):\n",
    "        Q = 600 m³/s, TF = 6.5°C → ṁ ≈ 9.5 m/day\n",
    "        Calculated: 0.142 × 600^0.31 × 6.5^1.19 = 9.57 m/day\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Merged discharge and temperature data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Input dataframe with added TF and SubmarineDischarge columns.\n",
    "    \"\"\"\n",
    "    df_calc = df.copy()\n",
    "    \n",
    "    # Thermal Forcing (TF) = Ocean Temperature - Pressure-Dependent Freezing Point\n",
    "    freezing_point = -1.9  # °C at ~300m depth\n",
    "    df_calc['TF'] = df_calc['Temp_Avg'] - freezing_point\n",
    "    \n",
    "    # Convert Runoff from m³/month to m³/s\n",
    "    df_calc['Runoff_m3s'] = df_calc['Runoff'] / SECONDS_PER_MONTH\n",
    "    \n",
    "    # Submarine Melt Rate (m/day)\n",
    "    df_calc['SubmarineDischarge'] = np.where(\n",
    "        (df_calc['Runoff_m3s'] > 0) & (df_calc['TF'] > 0),\n",
    "        0.142 * (df_calc['Runoff_m3s'] ** 0.31) * (df_calc['TF'] ** 1.19),\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    df_calc['TF'] = df_calc['TF'].round(3)\n",
    "    df_calc['SubmarineDischarge'] = df_calc['SubmarineDischarge'].round(2)\n",
    "    \n",
    "    # Drop intermediate conversion column (not needed in final output)\n",
    "    df_calc = df_calc.drop(columns=['Runoff_m3s'])\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n=== Submarine Melt Rate Summary (m/day) ===\")\n",
    "    for region in ['NE', 'SE']:\n",
    "        region_data = df_calc[df_calc['Region'] == region]['SubmarineDischarge']\n",
    "        print(f\"  {region}: Mean={region_data.mean():.2f}, \"\n",
    "              f\"Min={region_data.min():.2f}, Max={region_data.max():.2f}\")\n",
    "    \n",
    "    return df_calc\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Main Processing Pipeline\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Execute the full glacier-ocean data integration pipeline.\n",
    "\n",
    "    Steps:\n",
    "        1. Process discharge data (Karlsson et al., 2023)\n",
    "        2. Process temperature data (ORAS5 at 300m depth)\n",
    "        3. Merge discharge and temperature datasets\n",
    "        4. Calculate submarine melt rates (Slater & Straneo, 2022)\n",
    "        5. Save individual glacier and regional mean CSVs\n",
    "    \"\"\"\n",
    "    # Step 1: Process discharge data (Runoff & Ice Discharge)\n",
    "    print(\"=== Processing Discharge Data ===\")\n",
    "    discharge_df = process_discharge_data()\n",
    "    \n",
    "    # Step 2: Process temperature data (ORAS5 300m depth)\n",
    "    print(\"\\n=== Processing Temperature Data ===\")\n",
    "    temp_df = process_temperature_data()\n",
    "    \n",
    "    # Step 3: Merge discharge and temperature data\n",
    "    combined_df = pd.merge(discharge_df, temp_df, on=[\"Glacier\", \"Region\", \"Year\"], how=\"outer\")\n",
    "    \n",
    "    # Step 4: Calculate submarine melt rates (m/day)\n",
    "    # CRITICAL: Runoff is converted from m³/month to m³/s inside this function\n",
    "    print(\"\\n=== Calculating Submarine Melt Rates ===\")\n",
    "    combined_df = calculate_submarine_discharge(combined_df)\n",
    "    \n",
    "    # Step 5: Reorder columns for output CSV\n",
    "    column_order = [\n",
    "        \"Glacier\", \"Region\", \"Year\", \n",
    "        \"Runoff\", \"IceDischarge\",                   # m³/month (raw from Karlsson et al., 2023)\n",
    "        \"Temp_Avg\", \"Temp_Min\", \"Temp_Max\",         # °C at 300m depth (ORAS5)\n",
    "        \"TF\",                                        # °C (thermal forcing = Temp - freezing point)\n",
    "        \"SubmarineDischarge\",                        # m/day (Slater & Straneo, 2022)\n",
    "        \"Temp_Data_Points\"                           # Number of JJA months with valid data\n",
    "    ]\n",
    "    combined_df = combined_df[column_order]\n",
    "    \n",
    "    # Step 6: Save individual glacier data\n",
    "    individual_path = os.path.join(output_folder, \"individual_glaciers_summer.csv\")\n",
    "    combined_df.to_csv(individual_path, index=False)\n",
    "    print(f\"\\n  Individual glacier data saved: {individual_path}\")\n",
    "    \n",
    "    # Step 7: Calculate and save regional means\n",
    "    regional_means = combined_df.groupby(['Region', 'Year']).agg({\n",
    "        'Runoff': 'mean',\n",
    "        'IceDischarge': 'mean',\n",
    "        'Temp_Avg': 'mean',\n",
    "        'Temp_Min': 'min',\n",
    "        'Temp_Max': 'max',\n",
    "        'TF': 'mean',\n",
    "        'SubmarineDischarge': 'mean',\n",
    "        'Temp_Data_Points': 'sum'\n",
    "    }).reset_index().round(2)\n",
    "    \n",
    "    regional_path = os.path.join(output_folder, \"regional_means_summer.csv\")\n",
    "    regional_means.to_csv(regional_path, index=False)\n",
    "    print(f\"  Regional means data saved: {regional_path}\")\n",
    "    \n",
    "    # Print final data overview\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DATA SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Total records: {len(combined_df)}\")\n",
    "    print(f\"  Glaciers: {combined_df['Glacier'].nunique()}\")\n",
    "    print(f\"  Years: {combined_df['Year'].min()}-{combined_df['Year'].max()}\")\n",
    "    print(f\"  Columns: {list(combined_df.columns)}\")\n",
    "    print(f\"\\n  Note: Runoff and IceDischarge stored in m³/month (raw).\")\n",
    "    print(f\"        Convert to m³/s by dividing by {SECONDS_PER_MONTH:.0f} for plotting/analysis.\")\n",
    "    print(f\"        SubmarineDischarge is already in m/day (Q converted internally).\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"\\n=== All processing completed ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e1b3acd-3734-4c30-955c-92a86a8385b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INDIVIDUAL GLACIER CORRELATION ANALYSIS\n",
      "============================================================\n",
      "| Glacier                  | Region   | Temp vs Runoff (r)   | Temp vs IceDischarge (r)   | SubDischarge vs IceDischarge (r)   |\n",
      "|:-------------------------|:---------|:---------------------|:---------------------------|:-----------------------------------|\n",
      "| Helheim Gletsjer         | SE       | 0.288 (p=0.390)      | 0.064 (p=0.851)            | -0.024 (p=0.944)                   |\n",
      "| Storebjoern              | SE       | 0.605 (p=0.048)      | -0.423 (p=0.195)           | -0.406 (p=0.215)                   |\n",
      "| Daugaard-Jensen Gletsjer | NE       | -0.053 (p=0.877)     | -0.309 (p=0.356)           | -0.447 (p=0.168)                   |\n",
      "| Waltershausen Gletsjer   | NE       | -0.131 (p=0.701)     | 0.163 (p=0.632)            | 0.106 (p=0.757)                    |\n",
      "\n",
      "============================================================\n",
      "REGIONAL CORRELATION ANALYSIS\n",
      "============================================================\n",
      "| Region   | Temp vs Runoff (r)   | Temp vs IceDischarge (r)   | SubDischarge vs IceDischarge (r)   |\n",
      "|:---------|:---------------------|:---------------------------|:-----------------------------------|\n",
      "| NE       | -0.113 (p=0.740)     | -0.044 (p=0.897)           | -0.311 (p=0.352)                   |\n",
      "| SE       | 0.428 (p=0.189)      | -0.019 (p=0.955)           | -0.128 (p=0.708)                   |\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 5, Code 2: Statistical Correlation Analysis\n",
    "# =============================================================================\n",
    "# Pearson correlation tests at individual glacier and regional levels.\n",
    "# Reads pre-computed data from Section 5 Code 1 output CSVs.\n",
    "#\n",
    "# Key correlations:\n",
    "#   - Ocean Temperature vs Runoff\n",
    "#   - Ocean Temperature vs Ice Discharge\n",
    "#   - Submarine Melt Rate vs Ice Discharge (primary analytical test)\n",
    "#\n",
    "# All correlations reported to 3 decimal places (r and p-values).\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 1. Individual glacier analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"INDIVIDUAL GLACIER CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df = pd.read_csv('/Users/kyle/Documents/dissertation/Karlsson et al., 2023/tables/individual_glaciers_summer.csv')\n",
    "\n",
    "glacier_results = []\n",
    "for glacier in df['Glacier'].unique():\n",
    "    subset = df[df['Glacier'] == glacier]\n",
    "    \n",
    "    # Temperature correlations\n",
    "    r_corr, r_p = pearsonr(subset['Temp_Avg'], subset['Runoff'])\n",
    "    i_corr, i_p = pearsonr(subset['Temp_Avg'], subset['IceDischarge'])\n",
    "    \n",
    "    # Submarine Melt Rate vs Ice Discharge (primary test)\n",
    "    s_corr, s_p = pearsonr(subset['SubmarineDischarge'], subset['IceDischarge'])\n",
    "    \n",
    "    glacier_results.append({\n",
    "        'Glacier': glacier,\n",
    "        'Region': subset['Region'].iloc[0],\n",
    "        'Temp vs Runoff (r)': f\"{r_corr:.3f} (p={r_p:.3f})\",\n",
    "        'Temp vs IceDischarge (r)': f\"{i_corr:.3f} (p={i_p:.3f})\",\n",
    "        'SubDischarge vs IceDischarge (r)': f\"{s_corr:.3f} (p={s_p:.3f})\"\n",
    "    })\n",
    "\n",
    "print(pd.DataFrame(glacier_results).to_markdown(index=False))\n",
    "\n",
    "# 2. Regional analysis\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"REGIONAL CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df_reg = pd.read_csv('/Users/kyle/Documents/dissertation/Karlsson et al., 2023/tables/regional_means_summer.csv')\n",
    "\n",
    "region_results = []\n",
    "for region in df_reg['Region'].unique():\n",
    "    subset = df_reg[df_reg['Region'] == region]\n",
    "    \n",
    "    # Temperature correlations\n",
    "    r_corr, r_p = pearsonr(subset['Temp_Avg'], subset['Runoff'])\n",
    "    i_corr, i_p = pearsonr(subset['Temp_Avg'], subset['IceDischarge'])\n",
    "    \n",
    "    # Submarine Melt Rate vs Ice Discharge (primary test)\n",
    "    s_corr, s_p = pearsonr(subset['SubmarineDischarge'], subset['IceDischarge'])\n",
    "    \n",
    "    region_results.append({\n",
    "        'Region': region,\n",
    "        'Temp vs Runoff (r)': f\"{r_corr:.3f} (p={r_p:.3f})\",\n",
    "        'Temp vs IceDischarge (r)': f\"{i_corr:.3f} (p={i_p:.3f})\",\n",
    "        'SubDischarge vs IceDischarge (r)': f\"{s_corr:.3f} (p={s_p:.3f})\"\n",
    "    })\n",
    "\n",
    "print(pd.DataFrame(region_results).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ca9dcad-8c8d-4e91-aade-f1aa6f1e7e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runoff correlation plot saved to: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/runoff_temperature_correlation.png\n",
      "Ice discharge correlation plot saved to: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/icedischarge_temperature_correlation.png\n",
      "Submarine melt rate correlation plot saved to: /Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots/submarine_icedischarge_correlation.png\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Section 5, Code 3: Correlation Scatter Plots\n",
    "# =============================================================================\n",
    "# Three scatter plots with regression lines:\n",
    "#   (1) Runoff (m³/s) vs Potential Temperature (°C)\n",
    "#   (2) Ice Discharge (m³/s) vs Potential Temperature (°C)\n",
    "#   (3) Submarine Melt Rate (m/day) vs Ice Discharge (m³/s)  ← primary figure\n",
    "#\n",
    "# All hydrological variables converted from m³/month to m³/s at plot time.\n",
    "# Conversion: m³/s = m³/month ÷ (30.44 × 86400)\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\", font_scale=1.2)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "# Configuration\n",
    "output_folder = \"/Users/kyle/Documents/dissertation/Karlsson et al., 2023/plots\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Unit conversion constant: m³/month → m³/s\n",
    "SECONDS_PER_MONTH = 30.44 * 86400\n",
    "\n",
    "# Color scheme (consistent with other sections)\n",
    "REGION_COLORS = {'NE': '#d62728',  # Dark red\n",
    "                 'SE': '#1f77b4'}  # Dark blue\n",
    "\n",
    "# Custom legend (shared across all plots)\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', label='Northeast (NE)',\n",
    "           markerfacecolor=REGION_COLORS['NE'], markersize=10),\n",
    "    Line2D([0], [0], marker='o', color='w', label='Southeast (SE)',\n",
    "           markerfacecolor=REGION_COLORS['SE'], markersize=10)\n",
    "]\n",
    "\n",
    "# Load regional means data\n",
    "df = pd.read_csv('/Users/kyle/Documents/dissertation/Karlsson et al., 2023/tables/regional_means_summer.csv')\n",
    "\n",
    "# Pre-compute converted columns for plotting (m³/month → m³/s)\n",
    "df['Runoff_m3s'] = df['Runoff'] / SECONDS_PER_MONTH\n",
    "df['IceDischarge_m3s'] = df['IceDischarge'] / SECONDS_PER_MONTH\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Figure 1: Runoff (m³/s) vs Potential Temperature (°C)\n",
    "# =====================================================================\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "for region, color in REGION_COLORS.items():\n",
    "    subset = df[df['Region'] == region]\n",
    "    sns.regplot(x='Temp_Avg', y='Runoff_m3s', data=subset, \n",
    "                ax=ax1, color=color, scatter_kws={'s': 100, 'alpha': 0.7},\n",
    "                line_kws={'color': color, 'linestyle': '--'}, label=region)\n",
    "    \n",
    "    # Correlation text (3 decimal places)\n",
    "    r, p = pearsonr(subset['Temp_Avg'], subset['Runoff_m3s'])\n",
    "    ax1.text(0.05, 0.9 - 0.05 * list(REGION_COLORS.keys()).index(region), \n",
    "             f\"{region}: r = {r:.3f} (p = {p:.3f})\",\n",
    "             transform=ax1.transAxes, color=color, fontsize=12)\n",
    "\n",
    "ax1.set_title('Mean Summer (JJA) Runoff vs Mean Summer (JJA) Potential Temperature', \n",
    "              fontsize=16, pad=15, weight='bold')\n",
    "ax1.set_xlabel('Temperature (°C)', fontsize=14)\n",
    "ax1.set_ylabel('Runoff (m³/s)', fontsize=14)\n",
    "ax1.grid(True, linestyle=':', alpha=0.7)\n",
    "\n",
    "fig1.legend(handles=legend_elements, loc='upper center', \n",
    "           bbox_to_anchor=(0.5, 0.05), ncol=2, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "\n",
    "runoff_output_path = os.path.join(output_folder, \"runoff_temperature_correlation.png\")\n",
    "plt.savefig(runoff_output_path, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig1)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Figure 2: Ice Discharge (m³/s) vs Potential Temperature (°C)\n",
    "# =====================================================================\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "for region, color in REGION_COLORS.items():\n",
    "    subset = df[df['Region'] == region]\n",
    "    sns.regplot(x='Temp_Avg', y='IceDischarge_m3s', data=subset, \n",
    "                ax=ax2, color=color, scatter_kws={'s': 100, 'alpha': 0.7},\n",
    "                line_kws={'color': color, 'linestyle': '--'}, label=region)\n",
    "    \n",
    "    # Correlation text (3 decimal places)\n",
    "    r, p = pearsonr(subset['Temp_Avg'], subset['IceDischarge_m3s'])\n",
    "    ax2.text(0.05, 0.9 - 0.05 * list(REGION_COLORS.keys()).index(region), \n",
    "             f\"{region}: r = {r:.3f} (p = {p:.3f})\",\n",
    "             transform=ax2.transAxes, color=color, fontsize=12)\n",
    "\n",
    "ax2.set_title('Mean Summer (JJA) Ice Discharge vs Mean Summer (JJA) Potential Temperature', \n",
    "              fontsize=16, pad=15, weight='bold')\n",
    "ax2.set_xlabel('Temperature (°C)', fontsize=14)\n",
    "ax2.set_ylabel('Ice Discharge (m³/s)', fontsize=14)\n",
    "ax2.grid(True, linestyle=':', alpha=0.7)\n",
    "\n",
    "fig2.legend(handles=legend_elements, loc='upper center', \n",
    "           bbox_to_anchor=(0.5, 0.05), ncol=2, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "\n",
    "discharge_output_path = os.path.join(output_folder, \"icedischarge_temperature_correlation.png\")\n",
    "plt.savefig(discharge_output_path, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig2)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Figure 3: Submarine Melt Rate (m/day) vs Ice Discharge (m³/s)\n",
    "# This is the study's PRIMARY analytical figure.\n",
    "# =====================================================================\n",
    "\n",
    "fig3, ax3 = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "for region, color in REGION_COLORS.items():\n",
    "    subset = df[df['Region'] == region].copy()\n",
    "    \n",
    "    # Convert Ice Discharge to m³/s for y-axis\n",
    "    subset['IceDischarge_m3s'] = subset['IceDischarge'] / SECONDS_PER_MONTH\n",
    "    \n",
    "    sns.regplot(x='SubmarineDischarge', y='IceDischarge_m3s', data=subset, \n",
    "                ax=ax3, color=color, scatter_kws={'s': 100, 'alpha': 0.7},\n",
    "                line_kws={'color': color, 'linestyle': '--', 'linewidth': 2}, \n",
    "                label=region)\n",
    "    \n",
    "    # Correlation text (correlation is scale-invariant, same r whether m³/month or m³/s)\n",
    "    r, p = pearsonr(subset['SubmarineDischarge'], subset['IceDischarge'])\n",
    "    ax3.text(0.05, 0.9 - 0.05 * list(REGION_COLORS.keys()).index(region), \n",
    "             f\"{region}: r = {r:.3f} (p = {p:.3f})\",\n",
    "             transform=ax3.transAxes, color=color, fontsize=13, weight='bold')\n",
    "\n",
    "ax3.set_title('Mean Summer (JJA) Submarine Melt Rate vs Ice Discharge', \n",
    "              fontsize=17, pad=15, weight='bold')\n",
    "ax3.set_xlabel(r'Submarine Melt Rate (m/day) = $0.142 \\times Q^{0.31} \\times TF^{1.19}$', \n",
    "               fontsize=14, weight='bold')\n",
    "ax3.set_ylabel('Ice Discharge (m³/s)', fontsize=14, weight='bold')\n",
    "ax3.grid(True, linestyle=':', alpha=0.7)\n",
    "\n",
    "fig3.legend(handles=legend_elements, loc='upper center', \n",
    "           bbox_to_anchor=(0.5, 0.02), ncol=2, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "\n",
    "submarine_output_path = os.path.join(output_folder, \"submarine_icedischarge_correlation.png\")\n",
    "plt.savefig(submarine_output_path, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig3)\n",
    "\n",
    "print(f\"Runoff correlation plot saved to: {runoff_output_path}\")\n",
    "print(f\"Ice discharge correlation plot saved to: {discharge_output_path}\")\n",
    "print(f\"Submarine melt rate correlation plot saved to: {submarine_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da69564b-df05-41ae-8d64-949392b3f47d",
   "metadata": {},
   "source": [
    "## Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc2c4c-44ba-40d5-a04e-1b9eeee369f7",
   "metadata": {},
   "source": [
    "Copernicus Climate Data Store (CDS) (2021) ORAS5 Global Ocean Reanalysis Monthly Data from 1958 to Present. *Copernicus Climate Change Service (C3S)*. DOI: https://doi.org/10.24381/cds.67e8eeb7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05c4be-dd20-4797-bf6f-a0a44393281c",
   "metadata": {},
   "source": [
    "Google Earth (2025) *Maps showing the location of Helheim Gletsjer, Storebjoern, Daugaard-Jensen Gletsjer, and Waltershausen Gletsjer.* Available at: https://earth.google.com/web/@73.8999997,-24.41666671,248.07216786a,950.49443682d,35y,-0h,0t,0r/data=CgRCAggBOgMKATBCAggBSg0I____________ARAA (Accessed on 05-07-2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e90d8-2af4-475b-bd12-9c86c7095aaa",
   "metadata": {},
   "source": [
    "Google Maps API (2025) Google Terrain tiles Retrieved from https://mapsplatform.google.com/ (Accessed on 05-07-2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf52a6-7d3a-4d76-91c2-4466fac472aa",
   "metadata": {},
   "source": [
    "Jackson, R. H., Nash, J. D., Kienholz, C., Sutherland, D. A., Amundson, J. M., Motyka, R. J., Winters, D., Skyllingstad, E., Pettit, E. C. (2020). Meltwater Intrusions Reveal Mechanisms for Rapid Submarine Melt at a Tidewater Glacier. *Geophysical Research Letters*, 47, e2019GL085335. DOI: https://doi.org/10.1029/2019GL085335"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea19761-a285-49b0-ba94-4d74c91459fa",
   "metadata": {},
   "source": [
    "Jakobsson, M., Mohammad, R., Karlsson, M. et al. (2024) The International Bathymetric Chart of the Arctic Ocean Version 5.0. *Scientific Data*, 11, 1420. DOI: https://doi.org/10.1038/s41597-024-04278-w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839fcf33-477a-4c77-a50f-b4852ccba10d",
   "metadata": {},
   "source": [
    "Karlsson, N. B., Mankoff, K. D., Solgaard, A. M., Larsen, S. H., How, P. R., Fausto, R. S., Sørensen, L. S. (2023) A Data Set of Monthly Freshwater Fluxes from the Greenland Ice Sheet’s Marine-terminating Glaciers on a Glacier–Basin Scale 2010–2020. *Geological Survey of Denmark and Greenland*, 53, 8338. DOI: https://doi.org/10.34194/geusb.v53.8338"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e6253e-e9a9-44b9-a975-9a7c1c7751f9",
   "metadata": {},
   "source": [
    "Seale, A., Christoffersen, P., Mugford, R. I., O’Leary, M. (2011) Ocean Forcing of the Greenland Ice Sheet: Calving Fronts and Patterns of Retreat Identified by Automatic Satellite Monitoring of Eastern Outlet Glaciers. *Journal of Geophysical Research*, 116, F03015. DOI: https://doi.org/10.1029/2010JF001847"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75efd9f6-a8b7-4ba7-bc8b-f95ab5e65972",
   "metadata": {},
   "source": [
    "Slater, D.A. and Straneo, F. (2022) 'Submarine melting of glaciers in Greenland amplified by atmospheric warming', *Nature Geoscience*, 15(10), pp. 794–799. doi:10.1038/s41561-022-01035-9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92453c3c-c03b-435d-b4a2-aef8c69fdcbc",
   "metadata": {},
   "source": [
    "Straneo, F., Hamilton, G.S., Sutherland, D.A., Stearns, L.A., Davidson, F., Hammill, M.O., Stenson, G.B. and Rosing-Asvid, A. (2010) 'Rapid circulation of warm subtropical waters in a major glacial fjord in East Greenland', *Nature Geoscience*, 3(3), pp. 182–186. doi:10.1038/ngeo764."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
